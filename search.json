[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/flaskHW/index.html",
    "href": "posts/flaskHW/index.html",
    "title": "Homework 3: Flask",
    "section": "",
    "text": "https://github.com/jakebrowning02/PICHHW3 https://jakebrowning02.github.io/PIC16BHW/posts/flaskHW/\nWe will start the tutorial with the init.py file. The first function we see in this file is create_app(). The function effectively the creation of the app. As we can see, in the first line, we will set the app to be an instance of the Flask class that we imported at the top of the page. Next we begin to configure the app by defining where the database is to be located, by mapping the database to the ‘flaskBlog.sqlite’ file. If you are wishing to use a different file name for your database, that is fine, but just be sure to use that file name here instead of the one that I used. It is important to note, that for this we must import os at the top of the page. The function os.path.join shows the computer how to reach the file we have specified. Continuing downward, we see a hello() function. This function is not critical to this project, but is useful in checking that the app is working correctly and also happens to be an easier wsay to explain how these functions work. Above the function we see the command ‘@app.route(’/hello’)’ which is critical to this function. This ties the url route ‘/hello’ to this function, a practice we will use pervasively throughout this project. This page simply prints out ‘Hello, World!’, but other pages will have more complex applications. The following commands are all imports that we will revisit later after we have defined the functions that they are referring to. Let’s move over to the db.py file. This file is responsible for defining most of the basic commands necessary for setting up our database. The first thing we want to do is to import sqlite3. This allows us to make an sqlite3 database on this page. We will also import click for a later function, but more importantly, we import both current_app and g from the flask library. g is a special object that is able to be accessed by multiple functions, which is also unique for each request. Similarly, current_app is another special object that points to the Flask application handling the request. We will ensure that current_app will be able to be used by importing this file into the other .py files. The first function we see is get_db(). We first want to check that there is no database currently in our special instance g. If there is not, logically we want to begin to access the database. We define the database connection by creating an attribute db of g, and setting it to sqlite3.connect(), effectively making it a cursor we can use to search the database in later functions. We then return this attribute so that when we import it into other files, we can effectively use this as our cursor. The next function close_db() is rather self explanatory. We need a way to close the connection to the database if the database is open. We check if it is open by writing the if statement ‘if db is not None:’. This way, we only attempt to close the connection if it exists, which we do within the if statement by calling db.close(). We now come across our function that is called when we are intiating the database, init_db(). Using the function we just defined, we call get_db() to create a cursor, and using that we open the schematic that we write for the database, defining the tables, rows, columns, and titles to be held within the database. The next function gives us a way to call the function we just created. We call @click.command(‘init-db’) so that we can call the function using a command line command. Now, when we call this function via the command, we can see that it simply calls the init_db() function and recieve a message letting us know that we have successfully initialized the database. Finally, we come to the init_app() function. This function will be used to ensure that the cursor is closed when it needs to be. In order to ensure that the cursor is closed each time after returning a response, we will use the function teardown_appcontext(). This calls whatever function is within the parentheses whenever a response is returned, so we choose to call close_db() whenever a response is returned. Finally, we want to travel back to init.py and look at what we imported from this page. By importing db.init_app(app), we allow ourselves to initiate the database within the init.py file. Let us now take a look at our last .py file, blog.py. This file will contain most of what we see on the web app. We will import several useful methods from flask up top to be able to run our code. Taking a look at the first function index(), we see it appears to have a similar formate to the hello() function we saw before. Using the @bp.route(‘/’), we define the URL extension to be the backslash to access this page. First thing we do in this function is define db to be the cursor we get from the get_db() function we created in the previous page. Now, we will use this cursor to access the database. We now select both the author and body attributes from every post in the database, and set this list to be the list posts. This will be used in the html to show all of the posts that are contained within our database. This is useful for debugging and being able to view the database in a user friendly manner. Now we reach the return line of this function by calling render_template() we tell the computer to run the html file template we have created for this page called ‘index.html’. In my case, this file is contained within a blog folder, hence the ‘/blog’ before the ‘index.html’. We also choose to pass the posts list to the template as it is used to display the posts on this page. Continuing on, we get to the function used to insert new messages into the database. We see the function is associated with the URL extension ‘/submit’, however this time we also define the methods(‘GET’, ‘POST’), as any user request will be considered a ‘POST’. We check to make sure that this is the case via the if statement at the beginning of the function. Now we need to get input from the user so that we can input their name and their message. We do so by using the request.form[] function, allowing us to use the input to define the variables. We then check that the boxes have been filled, and send an error if they have not been. If everything is working well, we then use the get_db() function to access the cursor again and use it to insert the new message with its author into the database. We ensure to call db.commit() to save the new information into the database and call for a redirect. This function sends us back to the main page by calling the index function in the blog.py file, or in other words the function above this one. We also make sure to render the template for this page so that the html file we write will appear on this page. The random_messages function again uses the cursor we acquire from get_db(). We then use a special command for the cursor ‘RANDOM()’ to select the rows from the database in a random order. We use the variable n to determine how many rows are to be selected, and then set this to the list messages to be returned by this function. The view function is associated with its own URL and is the page used to determine how many random posts the user withes to see. We use request.form.get() to take in the user input. Then again, assuming no errors, we call random_messages function with the user inputted amount of function and pass it to our final function randomview(). This final function is associated with its own URL and gets random messages from the random_messages function. We call int(request.args.get(‘num_messages’)) to get the amount of messages desired by the user, a value passed by the previous page. Finally, we will take a look at our template for the new post page. First, we extend ‘base.html’ so that we can keep what we coded in that. We now define our header under the {%block header%} and set the block title to ‘New Messages’. Next, we get to the block content. We create a label titled ‘Author’ which is used for our input. This title is placed with the input text box that sends its input to the value request.form[‘author’] which we use to input the value into the database. We then do the same for the message, however this time we define a textarea to create a bigger box for the user to input their message. Finally, we create a submit button that says ‘Submit message’ for the user to click after they input their desired information."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/HW5/index.html",
    "href": "posts/HW5/index.html",
    "title": "Imports",
    "section": "",
    "text": "import os\nfrom keras import utils\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nThis block is where we will begin our imports to be used for this project. We then change the backend of keras to be tensorflow as it will allow for our image augmentation layers to run faster.\n\nimport keras\nfrom keras import layers\n\nWe have another import block in which we import keras and layers from keras. It is important that keras is imported after we change the backend to tensorflow, as that cannot be changed once keras has been imported.\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    #40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True, #Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nDownloading and preparing dataset 786.67 MiB (download: 786.67 MiB, generated: 1.04 GiB, total: 1.81 GiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\nDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\nNumber of training samples: 9305\nNumber of validation samples: 2326\nNumber of test samples: 2326\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\n\n\nThis block is used to access our data, as well as organizing it into datasets that will be used later. As we define our dataset names in the beginning as train_ds, validation_ds, and test_ds. We then call tfds.load, which loads datasets from the tensorflow_datasets library, which we then specify to be the “cats_vs_dogs” dataset. We then define splits for how much data will be implemented into each dataset. As you can see above, forty percent is dedicated to training, while only ten percent are allocated to both the validation and test datasets. Finally, we print out how many samples are in each dataset by calling the cardinality of each dataset. As expected, the number of training samples is approximately four times larger than that of the validation or testing datasets, which are themselves equal in size.\n\nresize_fn = keras.layers.Resizing(150,150)\n\ntrain_ds = train_ds.map(lambda x,y: (resize_fn(x),y))\nvalidation_ds = validation_ds.map(lambda x,y : (resize_fn(x),y))\ntest_ds = test_ds.map(lambda x,y:(resize_fn(x), y))\n\nWe now clean up our data a bit by creating a constant size for all samples. We can see that resize_fn calls a keras layer that resizes its input to be of size 150 x 150. We then use this layer to create lambda functions to be applied to all three of our datasets. We can now be sure of the dimensions of all of our samples in each of our datasets.\n\nfrom tensorflow import data as tf_data\nfrom tensorflow.keras.optimizers import Adam\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nThis block is a bit technical. We import tf_data to be used in this block, as well as an optimizer called Adam that we will not use until later. The batch_size variable we define determines how many data points are gathered from the directory at once."
  },
  {
    "objectID": "posts/HW5/index.html#imports",
    "href": "posts/HW5/index.html#imports",
    "title": "Imports",
    "section": "",
    "text": "import os\nfrom keras import utils\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nThis block is where we will begin our imports to be used for this project. We then change the backend of keras to be tensorflow as it will allow for our image augmentation layers to run faster.\n\nimport keras\nfrom keras import layers\n\nWe have another import block in which we import keras and layers from keras. It is important that keras is imported after we change the backend to tensorflow, as that cannot be changed once keras has been imported.\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    #40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True, #Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nDownloading and preparing dataset 786.67 MiB (download: 786.67 MiB, generated: 1.04 GiB, total: 1.81 GiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\nDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\nNumber of training samples: 9305\nNumber of validation samples: 2326\nNumber of test samples: 2326\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\n\n\nThis block is used to access our data, as well as organizing it into datasets that will be used later. As we define our dataset names in the beginning as train_ds, validation_ds, and test_ds. We then call tfds.load, which loads datasets from the tensorflow_datasets library, which we then specify to be the “cats_vs_dogs” dataset. We then define splits for how much data will be implemented into each dataset. As you can see above, forty percent is dedicated to training, while only ten percent are allocated to both the validation and test datasets. Finally, we print out how many samples are in each dataset by calling the cardinality of each dataset. As expected, the number of training samples is approximately four times larger than that of the validation or testing datasets, which are themselves equal in size.\n\nresize_fn = keras.layers.Resizing(150,150)\n\ntrain_ds = train_ds.map(lambda x,y: (resize_fn(x),y))\nvalidation_ds = validation_ds.map(lambda x,y : (resize_fn(x),y))\ntest_ds = test_ds.map(lambda x,y:(resize_fn(x), y))\n\nWe now clean up our data a bit by creating a constant size for all samples. We can see that resize_fn calls a keras layer that resizes its input to be of size 150 x 150. We then use this layer to create lambda functions to be applied to all three of our datasets. We can now be sure of the dimensions of all of our samples in each of our datasets.\n\nfrom tensorflow import data as tf_data\nfrom tensorflow.keras.optimizers import Adam\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nThis block is a bit technical. We import tf_data to be used in this block, as well as an optimizer called Adam that we will not use until later. The batch_size variable we define determines how many data points are gathered from the directory at once."
  },
  {
    "objectID": "posts/HW5/index.html#visualization",
    "href": "posts/HW5/index.html#visualization",
    "title": "Imports",
    "section": "Visualization",
    "text": "Visualization\n\ndef twoRowVis():\n    plt.figure(figsize=(10, 10))\n    for images, labels in train_ds.take(1):\n        dogNum = 0\n        catNum = 0\n\n        for i in range(32):\n            if labels[i].numpy() == 1 and dogNum &lt; 3:\n                ax = plt.subplot(2, 3, dogNum + 1)\n                plt.imshow(images[i].numpy().astype(\"uint8\"))\n                plt.title(f\"Label: {labels[i].numpy()}\")\n                plt.axis(\"off\")\n                dogNum += 1\n\n            elif labels[i].numpy() == 0 and catNum &lt; 3:\n                ax = plt.subplot(2, 3, 3 + catNum + 1)\n                plt.imshow(images[i].numpy().astype(\"uint8\"))\n                plt.title(f\"Label: {labels[i].numpy()}\")\n                plt.axis(\"off\")\n                catNum += 1\n\n            if dogNum == 3 and catNum == 3:\n                break\n\n    plt.show()\n    return\n\n\n\nAbove we have created a function for visualizing some of our images. We first set the size of the images by setting our figure size to (10,10). Now we need to access our images to be able to fill our plot. The method used to do this is take(1), which will retrieve one batch of images with labels, which we defined to be of size 64 in the previous code block. We will begin a for loop using these labels and images by calling for images and labels returned by the take method we call upon train_ds. It is critical to note that images containing dogs are labeled with a 1 while images with cats are labeled with a 0. Now that we have accessed our images, we wish to display a row of three images of dogs, followed by a row of three images with cats in them. In order to keep track of how many images of each have been displayed, we will create two variables titled numCats and numDogs respectively. We can now loop through and add images to a plot should they satisfy our criteria. We will first check if the image is a dog, by checking if the numpy attribute of the current label we are on is equal to 1. Additionally, we must check that we have not already entered the images for three dogs, by checking if numDog is less than three. Should this be true, we create a plot of dimensions (2,3) as we wish to have our plot contain two rows of three. We will then input this image into the plot at the first position. However as this is a loop, we cannot simply place 1, but rather we have to consider how the loop will deal with future images, which is where our numDogs variable will come in handy. We can send each image to the position 1+numDog in the plot, as they will each be placed one after another as we continually increment numDog. We can then use plt.imshow() to display our image, which can be called by using images[i].numpy(), as this image corresponds to the label we checked at the beginning of the if statement. Finally, we can set the title of our image to be label, turn off the axis, and increment our numDog and we are done with the first portion of our function. Placing our cats in the bottom row is very similar to what we just did, but with a few minor tweaks. First off, in our if statement condition, we want to ensure that the label is equal to 0, not 1. Secondly, as we want the cats to be on the bottom, we will add an extra three to their position in the plot, as they will then begin being placed in the bottom row. Other than that, as long as we make sure to use numCat in our position and incrementation instead of numDog, our cat placement should be complete. Finally, to ensure we finish as we place our final image in, we call a final if statement, where if both numCat and numDog are equal to or greater than three, we break out of our loop. After our loop has concluded, we can call plt.show() and our function is complete.\n\n# Calling visualization function defined above\ntwoRowVis()\n\n\n\n\n\n\n\n\nAs you can see, we call the function twoRowVis() that we created in the above code block, and it displays a row of three images with dogs followed by a row of three cat images. Notice how the labels above all the dogs are 1 and above all the cats are 0.\n\n# Creating a label iterator\nlabels_iterator=train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()\n\nWe now will create a label iterator so that we can check the number of cats and dogs in our training dataset. To do so, we unbatch train_ds to get all of our information, and then use a lambda function to extract just the labels. Finally we use the as_numpy_iterator() function to transform it into an iterator, yielding the iterator we title labels_iterator.\n\n# Compute the number of cats (labelled 0) and dogs (labelled 1) in training data\ncatCounter = 0\ndogCounter = 0\nfor label in labels_iterator:\n  if label==0:\n    catCounter = catCounter+1\n  elif label==1:\n    dogCounter = dogCounter+1\n\nprint(\"Number of cats is: \", catCounter)\nprint(\"Number of dogs is: \", dogCounter)\n\nNumber of cats is:  4637\nNumber of dogs is:  4668\n\n\nHere we use our label iterator that we made prviously to caluclate the number of cats and dogs in our training dataset. We will create two variables that will be used to count the number of cats and dogs in our dataset, titled catCounter and dogCounter. Recall that cats are distinguished with a label of 0 while dogs have a label of 1. We use this information to run through the iterator, incrementing the catCounter when we find a label equal to zero, and incrementing dogCounter when we encounter a label equal to one. Finally, we print out our results and find that there is a similar number of cat and dog images, 4,637 and 4,668 respectively.\nThis information can be used to estimate the accuracy of a baseline learning model, a model that simply guesses the most frequent label each time. As we can see, there are more dogs in this dataset, therefore the baseline would guess dog every time. We can calculate the accuracy by taking how many times it would be correct over the total samples, yielding 4,668/9,305= 0.50166, or approximately 50.166% accuracy."
  },
  {
    "objectID": "posts/HW5/index.html#first-model",
    "href": "posts/HW5/index.html#first-model",
    "title": "Imports",
    "section": "First Model",
    "text": "First Model\n\n# Create a sequential model\nmodel = keras.Sequential()\n\nmodel.add(layers.Input((150,150,3)))\n\n# Convolutional layers\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\n# Flatten layer to convert 2D feature maps to a vector\nmodel.add(layers.Flatten())\n\n# Fully connected layers\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))  # Dropout layer to prevent overfitting\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nmodel.add(layers.Dense(2))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel.summary()\n\n\nModel: \"sequential_42\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_10 (Conv2D)          (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_8 (MaxPoolin  (None, 74, 74, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_11 (Conv2D)          (None, 72, 72, 64)        18496     \n                                                                 \n max_pooling2d_9 (MaxPoolin  (None, 36, 36, 64)        0         \n g2D)                                                            \n                                                                 \n flatten_8 (Flatten)         (None, 82944)             0         \n                                                                 \n dense_11 (Dense)            (None, 128)               10616960  \n                                                                 \n dropout_4 (Dropout)         (None, 128)               0         \n                                                                 \n dense_12 (Dense)            (None, 2)                 258       \n                                                                 \n=================================================================\nTotal params: 10636610 (40.58 MB)\nTrainable params: 10636610 (40.58 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\nWe will now create our first keras sequential model. We start by initializing our model, titled model, to be an instance of keras.Sequential(). Now we can begin introducing our layers. Firstly, as we know the dimensions of each of our inputs, we can give this information to the model by adding an Input layer, specifying that each input will be of size (150,150,3). We know the dimensions as we resized each image earlier to be of size (150,150), and then each image has rgb coloring, representing the final dimension of size 3. We can now begin adding our convolutional layers to our model. We start by adding a layer called Conv2D. These layers effectively sharpen the image passed through them by increasing the contrast between pixels by passing them through a kernel. They slightly change the size of the image, as we can see in our summary above by looking at the input it is passed in and observing the difference between its output. We then implement several MaxPooling2D layers. Put somewhat simply, these down-sample the spatial dimensions of the input, while retaining most of the important information. After two iterations of both of those layers, we call a Flatten layer, which converts its input into a one dimension. This then allows us to call Dense layers, which require a flattened input. Our first dense layer has an argument of 128 passed to it, meaning it is functioning with 128 neurons. After our first dense layer, we implement a dropout layer which excludes various nodes with a probability passed into it, with the intention to combat overfitting. Finally, we call a dense layer with only two categories so that the model can determine if the test image is either a cat or dog. You may notice that several of the layers have an activation argument introduced. These activations are mathematical functions applied to the output of a layer which serve as a way to introduce non-linearity into our model. Additionally, in our final dense layer, we see an optimizer and loss argument. These serve to help the network know what kind of loss it should be trying to avoid, as well as adjust weights and learning rates in order to get a more accurate final result. At the end of this layer, we call metrics = [‘accuracy’] to ensure that we can access information on the accuracy when we train the model. Finally, we call model.summary() to get the representation of the model we see outputted above.\n\n# Train model1 here\nhistory = model.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 9s 45ms/step - loss: 34.4208 - accuracy: 0.5546 - val_loss: 0.6768 - val_accuracy: 0.5851\nEpoch 2/20\n146/146 [==============================] - 6s 41ms/step - loss: 0.6592 - accuracy: 0.6056 - val_loss: 0.6878 - val_accuracy: 0.5469\nEpoch 3/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5968 - accuracy: 0.6607 - val_loss: 0.7046 - val_accuracy: 0.5516\nEpoch 4/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5291 - accuracy: 0.7081 - val_loss: 0.7201 - val_accuracy: 0.5537\nEpoch 5/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.4597 - accuracy: 0.7640 - val_loss: 0.8601 - val_accuracy: 0.5542\nEpoch 6/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.4062 - accuracy: 0.7910 - val_loss: 1.0294 - val_accuracy: 0.5499\nEpoch 7/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.3546 - accuracy: 0.8291 - val_loss: 1.1475 - val_accuracy: 0.5641\nEpoch 8/20\n146/146 [==============================] - 5s 37ms/step - loss: 0.3557 - accuracy: 0.8409 - val_loss: 1.1655 - val_accuracy: 0.5817\nEpoch 9/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.2918 - accuracy: 0.8710 - val_loss: 1.3005 - val_accuracy: 0.5757\nEpoch 10/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.2714 - accuracy: 0.8818 - val_loss: 1.1921 - val_accuracy: 0.5980\nEpoch 11/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.2664 - accuracy: 0.8803 - val_loss: 1.3563 - val_accuracy: 0.5791\nEpoch 12/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.2197 - accuracy: 0.9113 - val_loss: 1.6582 - val_accuracy: 0.5959\nEpoch 13/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.2045 - accuracy: 0.9192 - val_loss: 1.4596 - val_accuracy: 0.5911\nEpoch 14/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1848 - accuracy: 0.9258 - val_loss: 1.5829 - val_accuracy: 0.5959\nEpoch 15/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1898 - accuracy: 0.9336 - val_loss: 1.4334 - val_accuracy: 0.6023\nEpoch 16/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.1580 - accuracy: 0.9423 - val_loss: 1.6742 - val_accuracy: 0.5954\nEpoch 17/20\n146/146 [==============================] - 6s 38ms/step - loss: 0.1628 - accuracy: 0.9394 - val_loss: 1.7273 - val_accuracy: 0.5911\nEpoch 18/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1370 - accuracy: 0.9485 - val_loss: 1.7679 - val_accuracy: 0.5795\nEpoch 19/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1312 - accuracy: 0.9556 - val_loss: 1.7821 - val_accuracy: 0.6010\nEpoch 20/20\n146/146 [==============================] - 5s 37ms/step - loss: 0.1199 - accuracy: 0.9583 - val_loss: 1.6738 - val_accuracy: 0.6062\n\n\nWe now will train our newly created model on our training dataset. We want to save this training so that we access the information later to get more information on how our training evolved over time. We initiate training with the fit() method, passing train_ds as an argument representing the dataset to train over, as well as the number of epochs we wish to run, and the validation dataset to test on after each dataset. We can note that our validation accuracy settled between 57% and 60% by the final epochs. This represents an improvement over our baseline which we calculated to have an accuracy of just over 50%. With regards to overfitting, we can observe there is definitely a prominent presence as our validation accuracy began to stagnate at around 60% while the training accuracy continued to improve, reaching above 95% accuracy. Note that the graph being referred to is displayed just below.\n\nplt.plot(history.history[\"accuracy\"])\nplt.plot(history.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nIn order to visualize how our model did, we plot the training accuracy as well as the validation accuracy accross each epoch. We can see in this case that our validation accuracy remained somewhat stagnant while our training accuracy continued to increase, a sign that overfitting became a significant factor."
  },
  {
    "objectID": "posts/HW5/index.html#second-model",
    "href": "posts/HW5/index.html#second-model",
    "title": "Imports",
    "section": "Second Model",
    "text": "Second Model\n\n#Demonstrate flipping\nmodelFlip = keras.Sequential()\nmodelFlip.add(layers.RandomFlip())\n\n\nfor images, labels in train_ds.take(1):\n    plt.subplot(1, 3, 1)\n    plt.imshow(images[0].numpy().astype(\"uint8\"))\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n    plt.subplot(1, 3, 2)\n    plt.imshow(modelFlip(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Flipped Image\")\n    plt.axis(\"off\")\n    plt.subplot(1, 3, 3)\n    plt.imshow(modelFlip(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Flipped Image\")\n    plt.axis(\"off\")\n    plt.show()\n\n\n\n\n\n\n\n\n\nIn this section we are experimenting with data augmentation layers, more specifically RandomFlip() and RandomRotation(). Starting with RandomFlip() we start of by making a model with just a RandomFlip() layer in it. We can demonstrate what this layer does by passing images through it and displaying what is outputted. On the left we see the first image from our train_ds dataset, shown using pyplot. To find out what happens when using the flipped layer, we display the same image, however when passing the image to imshow(), we apply the model to the image. What comes out is a reflected version of our original image, as you can see in the middle. We can do this same process one more time, and as we can see from the third image, we get another flipped version of our original image, however this one is flipped horizontally instead of vertically. If we do not pass any arguments to RandomFlip() we can see from the above images that it can flip the images both vertically and horizontally. Should we want it to only be able to flip images vertically we can pass the argument ‘vertical’ into the layer, and we will only get vertical flips.\n\n#Demonstrate rotating\nmodelRotate = keras.Sequential()\nmodelRotate.add(layers.RandomRotation(factor = 0.2))\n\n#plt.figure(figsize=(10,10))\n\nfor images, labels in train_ds.take(1):\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(images[0].numpy().astype(\"uint8\"))\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n    #plt.show()\n    ax = plt.subplot(1,3,2)\n    plt.imshow(modelRotate(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Rotated Image\")\n    plt.axis(\"off\")\n    #plt.show()\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(modelRotate(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Rotated Image\")\n    plt.axis(\"off\")\n    plt.show()\n\n\n\n\n\n\n\n\nSimilar to our RandomFlip() demonstration above, here we are showing what a RandomRotation() layer does to an image. Again, we have our original image on the left. We can see from the second image that when we apply a RandomRotation() layer to our image is slightly rotated, in this case clockwise. Running the image through the layer again results in a different rotation as seen in image three. The amount of rotation can be controlled by passing a rotation factor, in this case we used 0.2. This factor represents a factor of 2 Pi, which becomes the maximum roatation this layer will provide, given that 2 Pi is a complete spin.\n\n# Create a sequential model\nmodel2 = keras.Sequential()\nmodel2.add(layers.Input((150,150,3)))\n\n# Augmentation Layers\nmodel2.add(layers.RandomFlip('vertical'))\nmodel2.add(layers.RandomRotation(factor=0.2))\n\n\n# Convolutional layers\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel2.add(layers.Conv2D(32,(3,3), activation = 'relu'))\n# Dropout layer to prevent overfitting\nmodel2.add(layers.Dropout(0.1))\n\n# Flatten layer to convert 2D feature maps to a vector\nmodel2.add(layers.Flatten())\n\n# Fully connected layers\nmodel2.add(layers.Dense(64, activation='relu'))\n\n# Output layer\nmodel2.add(layers.Dense(2))\n\n# Compile the model\nmodel2.compile(optimizer=Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel2.summary()\n\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_1 (RandomFlip)  (None, 150, 150, 3)       0         \n                                                                 \n random_rotation_1 (RandomR  (None, 150, 150, 3)       0         \n otation)                                                        \n                                                                 \n conv2d_6 (Conv2D)           (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_5 (MaxPoolin  (None, 49, 49, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_7 (Conv2D)           (None, 47, 47, 32)        9248      \n                                                                 \n max_pooling2d_6 (MaxPoolin  (None, 15, 15, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_8 (Conv2D)           (None, 13, 13, 32)        9248      \n                                                                 \n max_pooling2d_7 (MaxPoolin  (None, 4, 4, 32)          0         \n g2D)                                                            \n                                                                 \n conv2d_9 (Conv2D)           (None, 2, 2, 32)          9248      \n                                                                 \n dropout_2 (Dropout)         (None, 2, 2, 32)          0         \n                                                                 \n flatten_2 (Flatten)         (None, 128)               0         \n                                                                 \n dense_4 (Dense)             (None, 64)                8256      \n                                                                 \n dense_5 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 37026 (144.63 KB)\nTrainable params: 37026 (144.63 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\nThe main difference in between this model and the first one we created is in the augmentation layers we have been experimenting with. These are introduced at the beginning of the model, just after we define the input shape. Other than that we are essentially just building upon our previous model, with a couple key exceptions. When looking at our output Dense layer, our optimizer is slightly different than before, as we have Adam(learning_rate=0.0001) instead of just ‘adam’. As one may expect, Adam and ‘adam’ refer to the same optimizer, however we are now customizing it a bit by passing a specific learning_rate. A lower learning rate puts less emphasis on each sample and epoch, although too small a learning rate would lead to a model that learns very slowly. On the other hand, should we have a learning rate that is too high, we can experience severe oscillations within different epochs as there is a larger emphasis placed on each sample. It is important to find a good medium, and in our case, 0.0001 worked well for us to achieve our desired accuracy.\n\n# Train model2 here\nhistory2 = model2.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 10s 35ms/step - loss: 2.5473 - accuracy: 0.5241 - val_loss: 0.9332 - val_accuracy: 0.5279\nEpoch 2/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.8300 - accuracy: 0.5211 - val_loss: 0.7367 - val_accuracy: 0.5370\nEpoch 3/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.7409 - accuracy: 0.5369 - val_loss: 0.7065 - val_accuracy: 0.5610\nEpoch 4/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.7085 - accuracy: 0.5564 - val_loss: 0.6812 - val_accuracy: 0.5847\nEpoch 5/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6920 - accuracy: 0.5764 - val_loss: 0.6745 - val_accuracy: 0.5920\nEpoch 6/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6795 - accuracy: 0.5919 - val_loss: 0.6899 - val_accuracy: 0.5671\nEpoch 7/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6738 - accuracy: 0.5945 - val_loss: 0.6642 - val_accuracy: 0.6045\nEpoch 8/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6673 - accuracy: 0.5981 - val_loss: 0.6582 - val_accuracy: 0.6182\nEpoch 9/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6617 - accuracy: 0.6088 - val_loss: 0.6654 - val_accuracy: 0.5942\nEpoch 10/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6581 - accuracy: 0.6097 - val_loss: 0.6465 - val_accuracy: 0.6225\nEpoch 11/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6542 - accuracy: 0.6292 - val_loss: 0.6423 - val_accuracy: 0.6225\nEpoch 12/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6486 - accuracy: 0.6240 - val_loss: 0.6381 - val_accuracy: 0.6359\nEpoch 13/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.6472 - accuracy: 0.6302 - val_loss: 0.6160 - val_accuracy: 0.6647\nEpoch 14/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.6372 - accuracy: 0.6419 - val_loss: 0.6032 - val_accuracy: 0.6737\nEpoch 15/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.6298 - accuracy: 0.6460 - val_loss: 0.6041 - val_accuracy: 0.6741\nEpoch 16/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6194 - accuracy: 0.6629 - val_loss: 0.6151 - val_accuracy: 0.6582\nEpoch 17/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6200 - accuracy: 0.6600 - val_loss: 0.5982 - val_accuracy: 0.6720\nEpoch 18/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6175 - accuracy: 0.6625 - val_loss: 0.5862 - val_accuracy: 0.6909\nEpoch 19/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6087 - accuracy: 0.6674 - val_loss: 0.5969 - val_accuracy: 0.6857\nEpoch 20/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.6002 - accuracy: 0.6790 - val_loss: 0.6147 - val_accuracy: 0.6745\n\n\nWe now will train our newly created model2 on our training dataset. We again want to save our training information so that we can analyze it afterwards. Similar to last time, we initiate training with the fit() method, passing train_ds as an argument representing the dataset to train over, as well as the number of epochs we wish to run, and the validation dataset to test on after each dataset, however this time we pass it to model2. We can note that our validation accuracy settled between 65% and 70% by the final epochs. This represents an improvement over our first model which we calculated to have an accuracy of between 57% and 60%. With regards to overfitting, there is not nearly as large of an issue as there was in our first model. Taking a look at the graph depicting training and validation accuracy, we can see that they have a similar trend and remain relatively close to each other throughout the epochs. Note that the graph being referred to is displayed just below.\n\n# Visualize training history for model2\nplt.plot(history2.history['accuracy'])\nplt.plot(history2.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nWe run the same code we did last time to plot our training and validation accuracy, except this time calling history2 instead of history. As we can observe, our validation and training accuracies move much more in unison than they did in the previous model."
  },
  {
    "objectID": "posts/HW5/index.html#third-model",
    "href": "posts/HW5/index.html#third-model",
    "title": "Imports",
    "section": "Third Model",
    "text": "Third Model\n\ni = keras.Input(shape=(150, 150, 3))\n# The pixel values have the range of (0, 255), but many models will work better if rescaled to (-1, 1.)\n# outputs: `(inputs * scale) + offset`\nscale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\nx = scale_layer(i)\npreprocessor = keras.Model(inputs = i, outputs = x)\n\nHere we are defining a preprocessor that modifies the data before running it through the rest of the model. In this case scenario, we are changing the pixel values from a scale of (0,255), to a scale of (-1,1). Often, models work better when working with this kind of scale. We can see how this is achieved as each shape is rescaled by dividing by 127.5, which puts all pixels in the range of (0,2), and then we offset by -1 to shift the range to (-1,1).\n\n# Create a sequential model\nmodel3 = keras.Sequential()\nmodel3.add(layers.Input((150,150,3)))\n\n# Augmentation Layers\nmodel3.add(layers.RandomFlip('vertical'))\nmodel3.add(layers.RandomRotation(factor=0.2))\n\n# Adding preprocessor layer defined above\nmodel3.add(preprocessor)\n\n# Convolutional layers\nmodel3.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel3.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel3.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel3.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel3.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel3.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel3.add(layers.Conv2D(32, (3,3), activation = 'relu'))\n\n# Dropout layer to prevent overfitting\nmodel3.add(layers.Dropout(0.1))\n\n# Flatten layer to convert 2D feature maps to a vector\nmodel3.add(layers.Flatten())\n\n# Fully connected layers\nmodel3.add(layers.Dense(64, activation='relu'))\n\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nmodel3.add(layers.Dense(2))\n\n# Compile the model\nmodel3.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel3.summary()\n\n\nModel: \"sequential_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_4 (RandomFlip)  (None, 150, 150, 3)       0         \n                                                                 \n random_rotation_4 (RandomR  (None, 150, 150, 3)       0         \n otation)                                                        \n                                                                 \n model (Functional)          (None, 150, 150, 3)       0         \n                                                                 \n conv2d_14 (Conv2D)          (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_11 (MaxPooli  (None, 49, 49, 32)        0         \n ng2D)                                                           \n                                                                 \n conv2d_15 (Conv2D)          (None, 47, 47, 32)        9248      \n                                                                 \n max_pooling2d_12 (MaxPooli  (None, 15, 15, 32)        0         \n ng2D)                                                           \n                                                                 \n conv2d_16 (Conv2D)          (None, 13, 13, 32)        9248      \n                                                                 \n max_pooling2d_13 (MaxPooli  (None, 4, 4, 32)          0         \n ng2D)                                                           \n                                                                 \n conv2d_17 (Conv2D)          (None, 2, 2, 32)          9248      \n                                                                 \n dropout_4 (Dropout)         (None, 2, 2, 32)          0         \n                                                                 \n flatten_5 (Flatten)         (None, 128)               0         \n                                                                 \n dense_9 (Dense)             (None, 64)                8256      \n                                                                 \n dense_10 (Dense)            (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 37026 (144.63 KB)\nTrainable params: 37026 (144.63 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\nThe main difference between this model and model2 is that we are including the preprocessor we defined above. It is important to note that we are still including the data augmentation layers and have placed those before the preprocessor. This is because the job that the augmentation play is to slightly vary the data, which should then be passed to the preprocessor so it can take the varied data and apply the scale change to it. Looking closely we can see that we have applied the ‘vertical’ argument to the RandomFlip() layer, which we learned earlier allows RandomFlip() to flip layers vertically but not horizontally. Other than that, all of the key elements have remained the same from the previous model, so we are counting on the preprocessor to improve the results of our model.\n\n# Train model3 here\nhistory3 = model3.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 7s 32ms/step - loss: 0.6721 - accuracy: 0.5799 - val_loss: 0.6273 - val_accuracy: 0.6509\nEpoch 2/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6251 - accuracy: 0.6531 - val_loss: 0.5766 - val_accuracy: 0.7008\nEpoch 3/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.5853 - accuracy: 0.6901 - val_loss: 0.5497 - val_accuracy: 0.7227\nEpoch 4/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5628 - accuracy: 0.7116 - val_loss: 0.5517 - val_accuracy: 0.7283\nEpoch 5/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.5452 - accuracy: 0.7232 - val_loss: 0.5312 - val_accuracy: 0.7446\nEpoch 6/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5285 - accuracy: 0.7347 - val_loss: 0.5059 - val_accuracy: 0.7597\nEpoch 7/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5290 - accuracy: 0.7347 - val_loss: 0.5148 - val_accuracy: 0.7584\nEpoch 8/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5109 - accuracy: 0.7501 - val_loss: 0.4911 - val_accuracy: 0.7747\nEpoch 9/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4972 - accuracy: 0.7546 - val_loss: 0.4780 - val_accuracy: 0.7799\nEpoch 10/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.4840 - accuracy: 0.7663 - val_loss: 0.4727 - val_accuracy: 0.7859\nEpoch 11/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4729 - accuracy: 0.7737 - val_loss: 0.4895 - val_accuracy: 0.7752\nEpoch 12/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4692 - accuracy: 0.7758 - val_loss: 0.4460 - val_accuracy: 0.7984\nEpoch 13/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.4573 - accuracy: 0.7876 - val_loss: 0.4501 - val_accuracy: 0.7889\nEpoch 14/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4480 - accuracy: 0.7920 - val_loss: 0.4467 - val_accuracy: 0.8005\nEpoch 15/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.4434 - accuracy: 0.7927 - val_loss: 0.4472 - val_accuracy: 0.7932\nEpoch 16/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4353 - accuracy: 0.8023 - val_loss: 0.4259 - val_accuracy: 0.8083\nEpoch 17/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4281 - accuracy: 0.8041 - val_loss: 0.4346 - val_accuracy: 0.8027\nEpoch 18/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.4214 - accuracy: 0.8086 - val_loss: 0.4200 - val_accuracy: 0.8074\nEpoch 19/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4170 - accuracy: 0.8040 - val_loss: 0.4198 - val_accuracy: 0.8065\nEpoch 20/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.4091 - accuracy: 0.8082 - val_loss: 0.4084 - val_accuracy: 0.8156\n\n\nAfter training model3, we can see that our preprocessor did in fact make a difference. After fitting the model on our training dataset as we did previously and saving the information to history3, we see an improvement in accuracy. For this model, our validation accuracy settled between 80% and 82% by the final epochs. This represents an even more drastic improvement over our first model which we calculated to have an accuracy of between 57% and 60%. With regards to overfitting, there is not nearly as large of an issue as there was in our first model. When looking at the graph depicting training and validation accuracy, we note that they remain very close to each other throughout the training, even closer than our second model was. Note that the graph being referred to is displayed just below.\n\n# Visualize training history for model2\nplt.plot(history3.history['accuracy'])\nplt.plot(history3.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nAgain we are using saved information in history3 to visualize our training history. We can see that in this case our validation and training accuracy appear to be even closer than they have been before,"
  },
  {
    "objectID": "posts/HW5/index.html#fourth-model",
    "href": "posts/HW5/index.html#fourth-model",
    "title": "Imports",
    "section": "Fourth Model",
    "text": "Fourth Model\n\nIMG_SHAPE = (150, 150, 3)\nbase_model = keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model.trainable = False\n\ni = keras.Input(shape=IMG_SHAPE)\nx = base_model(i, training = False)\nbase_model_layer = keras.Model(inputs = i, outputs = x)\n\nWARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n12683000/12683000 [==============================] - 0s 0us/step\n\n\nIn this model we plan on implementing a pre-existing model to see if it can improve our accuracy. Above we are reading in the model, titled base_model, from keras, and passing it the shape of our images via the variable IMG_SHAPE. We will then implement this base layer into our model.\n\n\n\n# Create a sequential model\nmodel4 = keras.Sequential()\nmodel4.add(layers.Input((150,150,3)))\n\n\n# Augmentation Layers\nmodel4.add(layers.RandomFlip())\nmodel4.add(layers.RandomRotation(factor=10.0))\n\n# Adding layer defined above\nmodel4.add(base_model_layer)\n\n#Flatten\nmodel4.add(layers.Flatten())\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nmodel4.add(layers.Dense(2))\n\n# Compile the model\nmodel4.compile(optimizer=Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel4.summary()\n\n\nModel: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_2 (RandomFlip)  (None, 150, 150, 3)       0         \n                                                                 \n random_rotation_2 (RandomR  (None, 150, 150, 3)       0         \n otation)                                                        \n                                                                 \n model_1 (Functional)        (None, 5, 5, 960)         2996352   \n                                                                 \n flatten_3 (Flatten)         (None, 24000)             0         \n                                                                 \n dense_6 (Dense)             (None, 2)                 48002     \n                                                                 \n=================================================================\nTotal params: 3044354 (11.61 MB)\nTrainable params: 48002 (187.51 KB)\nNon-trainable params: 2996352 (11.43 MB)\n_________________________________________________________________\n\n\nAs we can observem, this model appears to be much simpler than the previous models we created. Just by looking at the summary we would assume so as it is simply much shorter than the other ones. However we must take into account the fact that we have an entirely separate model built into this one we just created. While we have not included any Conv2D or Pooling2D layers in this model, it is important to note that we have still included our augmentation layers, as well as a Flatten layer followed by a Dense layer to give us our output. You may be wondering why we decided not to include our preprocessor that we introduced in the previous model. The reason is that the base_model_layer that we just added includes its own preprocessing layers, eliminating the need for us to introduce more. Now that we have created our model4, we can train it and see what kind of improvements this new model will experience.\n\n# Train model4 here\nhistory4 = model4.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 15s 65ms/step - loss: 0.5579 - accuracy: 0.8296 - val_loss: 0.2166 - val_accuracy: 0.9428\nEpoch 2/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3273 - accuracy: 0.9033 - val_loss: 0.2017 - val_accuracy: 0.9450\nEpoch 3/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.2922 - accuracy: 0.9110 - val_loss: 0.1732 - val_accuracy: 0.9518\nEpoch 4/20\n146/146 [==============================] - 6s 45ms/step - loss: 0.2633 - accuracy: 0.9192 - val_loss: 0.1664 - val_accuracy: 0.9518\nEpoch 5/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.2566 - accuracy: 0.9207 - val_loss: 0.1875 - val_accuracy: 0.9484\nEpoch 6/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.2350 - accuracy: 0.9254 - val_loss: 0.1847 - val_accuracy: 0.9480\nEpoch 7/20\n146/146 [==============================] - 7s 48ms/step - loss: 0.2170 - accuracy: 0.9316 - val_loss: 0.1949 - val_accuracy: 0.9497\nEpoch 8/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.2110 - accuracy: 0.9327 - val_loss: 0.1599 - val_accuracy: 0.9523\nEpoch 9/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.2034 - accuracy: 0.9344 - val_loss: 0.1425 - val_accuracy: 0.9561\nEpoch 10/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1978 - accuracy: 0.9381 - val_loss: 0.1415 - val_accuracy: 0.9561\nEpoch 11/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1816 - accuracy: 0.9387 - val_loss: 0.1616 - val_accuracy: 0.9506\nEpoch 12/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1700 - accuracy: 0.9424 - val_loss: 0.1419 - val_accuracy: 0.9609\nEpoch 13/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1661 - accuracy: 0.9466 - val_loss: 0.1701 - val_accuracy: 0.9506\nEpoch 14/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1755 - accuracy: 0.9364 - val_loss: 0.1695 - val_accuracy: 0.9536\nEpoch 15/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1624 - accuracy: 0.9430 - val_loss: 0.1845 - val_accuracy: 0.9484\nEpoch 16/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1585 - accuracy: 0.9477 - val_loss: 0.1422 - val_accuracy: 0.9561\nEpoch 17/20\n146/146 [==============================] - 7s 47ms/step - loss: 0.1541 - accuracy: 0.9461 - val_loss: 0.1587 - val_accuracy: 0.9523\nEpoch 18/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1592 - accuracy: 0.9496 - val_loss: 0.1443 - val_accuracy: 0.9592\nEpoch 19/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1468 - accuracy: 0.9455 - val_loss: 0.1574 - val_accuracy: 0.9579\nEpoch 20/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1534 - accuracy: 0.9477 - val_loss: 0.1596 - val_accuracy: 0.9531\n\n\nAfter again fitting the model on our training dataset as we did previously and saving the information, we see a drastic improvement in our accuracy, largely due to the new model that we built off of. For this model, our validation accuracy settled between 94% and 96% by the final epochs. This represents a massive drastic improvement over our first model which we calculated to have an accuracy of between 57% and 60%. In fact, this is also a massive improvement over our second model, as we jumped up from around 80%. With regards to overfitting, we can see that the validation in fact experiences much higher accuracy rates than the training sets did. This is not typically a sign of overfitting, as for an overfit model normally the opposite is true. Note that the graph being referred to is displayed just below.\n\n# Visualize training history for model4\nplt.plot(history4.history['accuracy'])\nplt.plot(history4.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nAfter again graphing the training and validation accuracies, we can see that this most recent model has had by far the most success in predicting dogs and cats, peaking at around 94% success for training and 96% for validation. It is somewhat curious that the validation has a higher accuracy rate than the training does, as typically it is the other way around."
  },
  {
    "objectID": "posts/HW5/index.html#final-model",
    "href": "posts/HW5/index.html#final-model",
    "title": "Imports",
    "section": "Final Model",
    "text": "Final Model\n\n#Create model and test against test dataset\nfinalModel = keras.Sequential()\n\nfinalModel.add(layers.Input((150,150,3)))\n\n\n# Augmentation Layers\nfinalModel.add(layers.RandomFlip())\nfinalModel.add(layers.RandomRotation(factor=0.2))\n\n# Adding layer defined above\nfinalModel.add(base_model_layer)\n\n#Adding convolution layer\nfinalModel.add(layers.GlobalMaxPooling2D())\n#finalModel.add(layers.Dropout(0.1))\n\n#Flatten\nfinalModel.add(layers.Flatten())\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nfinalModel.add(layers.Dense(2))\n\n# Compile the model\nfinalModel.compile(optimizer=Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nfinalModel.summary()\n\nModel: \"sequential_41\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_23 (RandomFlip  (None, 150, 150, 3)       0         \n )                                                               \n                                                                 \n random_rotation_25 (Random  (None, 150, 150, 3)       0         \n Rotation)                                                       \n                                                                 \n model_1 (Functional)        (None, 5, 5, 960)         2996352   \n                                                                 \n global_max_pooling2d_2 (Gl  (None, 960)               0         \n obalMaxPooling2D)                                               \n                                                                 \n flatten_7 (Flatten)         (None, 960)               0         \n                                                                 \n dense_10 (Dense)            (None, 2)                 1922      \n                                                                 \n=================================================================\nTotal params: 2998274 (11.44 MB)\nTrainable params: 1922 (7.51 KB)\nNon-trainable params: 2996352 (11.43 MB)\n_________________________________________________________________\n\n\nFor our final model we are trying to get as accurate as possible. Seeing as our most recent model had an accuracy of around 95%, it does not make sense to deviate too much from that model. Hence, this model is very reminiscent of our previous one, with a couple of tweaks. After our base_model_layer, we have added a convolution layer, GlobalMaxPooling2D, and then from there it remains the same as before. Time to see how well our new model performs.\n\n# Train finalModel here\nfinalHistory = finalModel.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 12s 52ms/step - loss: 3.6604 - accuracy: 0.6235 - val_loss: 1.7367 - val_accuracy: 0.7747\nEpoch 2/20\n146/146 [==============================] - 7s 46ms/step - loss: 1.8534 - accuracy: 0.7533 - val_loss: 0.8666 - val_accuracy: 0.8706\nEpoch 3/20\n146/146 [==============================] - 7s 45ms/step - loss: 1.3031 - accuracy: 0.8169 - val_loss: 0.6475 - val_accuracy: 0.9007\nEpoch 4/20\n146/146 [==============================] - 6s 44ms/step - loss: 1.0832 - accuracy: 0.8459 - val_loss: 0.5191 - val_accuracy: 0.9187\nEpoch 5/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.9933 - accuracy: 0.8535 - val_loss: 0.4821 - val_accuracy: 0.9256\nEpoch 6/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.8703 - accuracy: 0.8693 - val_loss: 0.3995 - val_accuracy: 0.9359\nEpoch 7/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.8153 - accuracy: 0.8743 - val_loss: 0.3618 - val_accuracy: 0.9398\nEpoch 8/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.7676 - accuracy: 0.8766 - val_loss: 0.3670 - val_accuracy: 0.9428\nEpoch 9/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.7150 - accuracy: 0.8825 - val_loss: 0.3418 - val_accuracy: 0.9458\nEpoch 10/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.6984 - accuracy: 0.8853 - val_loss: 0.3390 - val_accuracy: 0.9471\nEpoch 11/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.6224 - accuracy: 0.8936 - val_loss: 0.3150 - val_accuracy: 0.9493\nEpoch 12/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.6338 - accuracy: 0.8944 - val_loss: 0.2945 - val_accuracy: 0.9510\nEpoch 13/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.5575 - accuracy: 0.8991 - val_loss: 0.2715 - val_accuracy: 0.9514\nEpoch 14/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.5561 - accuracy: 0.8985 - val_loss: 0.2700 - val_accuracy: 0.9527\nEpoch 15/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.5171 - accuracy: 0.9018 - val_loss: 0.2562 - val_accuracy: 0.9540\nEpoch 16/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.5165 - accuracy: 0.9047 - val_loss: 0.2451 - val_accuracy: 0.9570\nEpoch 17/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.4918 - accuracy: 0.9060 - val_loss: 0.2509 - val_accuracy: 0.9553\nEpoch 18/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.4613 - accuracy: 0.9084 - val_loss: 0.2300 - val_accuracy: 0.9549\nEpoch 19/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.4452 - accuracy: 0.9079 - val_loss: 0.2413 - val_accuracy: 0.9553\nEpoch 20/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.4585 - accuracy: 0.9066 - val_loss: 0.2471 - val_accuracy: 0.9544\n\n\nWe can see that this model again experienced exceptional accuracy, settling at around 95% for the validation sets. However this time we are going to go a step further and test it on our test_ds dataset that we are yet to use.\n\n# Visualize training history for finalModel\nplt.plot(finalHistory.history['accuracy'])\nplt.plot(finalHistory.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nAfter again plotting validatin and training accuracy throughout the training process, it makes sense that this graph appears similar to that of our previous model, as the two models are very similar in nature.\n\nfinalModel.evaluate(test_ds)\n\n37/37 [==============================] - 1s 33ms/step - loss: 0.3433 - accuracy: 0.9441\n\n\n[0.3432992398738861, 0.9441100358963013]\n\n\nTo test our model on our test dataset, we call then method evaluate() and pass it test_ds, so that it knows what to test our model on. We can see that we achieve an accuracy of just over 94%, a very respectable result indeed."
  },
  {
    "objectID": "posts/HW4/index.html",
    "href": "posts/HW4/index.html",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "",
    "text": "Comparison of methods\nWhen looking at the four methods that we have implemented, it is clear that the advance_time_matvecmul() method is by far the slowest at 1 minute and 39 seconds per loop while our final method, advance_time_jax() is the fastest at a mere 291 ms per loop. The method advance_time_numpy() and advance_time_jax() may seem relatively similar in speeds as there is less than a second separating their time to progress 2700 time steps, however in reality the jax method is a little less than twice as fast as the numpy method, at times of 291 ms and 520 ms respectively. That being said, they are both significantly faster than the sparse_advance_time_matvecmul() method at 1.7 seconds per loop , which itself is still much faster than the advance_time_matvecmul() which, as stated before, took approximately 1 minute and 39 seconds to advance our model through 2700 timesteps.\nWhen it comes to writing the functions, taking into account that I did not write the first method, I found the get_sparse_A() method the easiest to write, as I was simply building on the get_A() method I had previously written, and then writing one line to set my return value to a sparse matrix corresponding to the matrix returned by the get_A() function. Similarly, the get_A() function was relatively straightforward to write as I simply had to create a matrix and then edit three of the diagonals. I initially had some trouble when writing the advance_time_numpy() function as I was unsure of how to implement the boundary conditions that were to allow heat to escape from the model. Before successfully completing the boundary condition, my results yielded a heat map that began to take on an almost plus-like shape as the heat began to reach the edges and simply wrap around to the other side. I solved this problem by creating a matrix of dimensions (N+2)x(N+2), which allowed the heat to go to an outer ring that was effectively deleted before returning the function, simulating the idea that the heat escaped outside of our model. Similar to the get_A_sparse() function, after writing the advance_time_numpy() function the advance_time_jax() function was relatively easy to implement. Conceptually it follows the same pattern as the numpy function, with the only catch being that jax does not allow for index assignment. To get around this, I found a function .at(), helping me to navigate around the matrices, and more importantly, I created new matrices at each step, meaning I was not altering any pre-existing matrices, but rather creating new ones which is allowed by jax.\nBlog Tutorial\nToday we will create a simulation of two-dimensional heat diffusion using packages such as jax and numpy. Let us start by creating two jupyter notebooks, one titled heat_equation.ipynb, and the other jax_heat_map.ipynb. We will store our important methods in heat_equation.ipynb, while jax_heat_map.ipynb will be used to test them as we import them in.\nStarting in heat_equation.ipynb, let us start by importing the packages we plan on using in this project: jax, numpy, sparse from jax.experimental, jit from jax, and jax.numpy. I chose to import numpy as np and jax numpy as jnp to make them easier to use as we will be using them a fair amount. We are now ready to begin implementing our first method advance_time_matvecmul(). For this function we will take in three arguments, A, u, and epsilon. It is important to familiarize ourselves with what these variables represent in the model as they will be used pervasively throughout the process. The value A represents the transition matrix to be used. The variable u represents an N x N matrix that is the current state of our heat map. We will find soon that initially u, at time zero called u0, is a simple point in the middle of the matrix. In order to update to the next timestep, we will use A, which is a numpy array of size N2 x N2. By finding the product of A and u, we find what kind of change is to be seen when moving to the next timestep. Finally, epsilon tells us the magnitude of that change. Therefore, the change we see between timesteps is given by the epsilon(Au). Finally, to get to the next timestep, we simply add the change to our current state, u, to the change we just found, setting this all equal to a new u to get to our next time step.\nNow that we understand the math behind what we are trying to simulate, we can get back to our advance_time_matvecmul() function in heat_equation.ipynb, which is passed in the three parameters u, A, and epsilon. The purpose of this function is to simply advance us one timestep in the simulation, returning the value u representing the new heat map. Luckily, we know how to do that given our discussion in the previous paragraph. By simply using the equation we found, we can set u equal to u + epsilon(Au), however there are some technicalities that we need to deal with. Firstly, we need to use the u.flatten() function when finding the product of A and u as otherwise we will encounter an error due to differences in dimensions between A and u. When flattened, u becomes a one dimensional array of size N2, allowing for the product to be calculated by multiplying by an N2 x N2 matrix, namely A. Unfortunately, to return a reasonable u, we need a matrix that is of the dimensions N x N, similar to the u we were passed in. To get our flattened product of A and u back into the form of an N x N matrix we can use the .reshape(A,B) function which will revert the product back into an A X B matrix. It seems that we could simply replace A and B in this function with N and N as we know those are the dimensions of our desired matrix, however we must be careful here as there was no value N passed into this function. While a global N may have been declared, it is safer to use the shape of u passed in to calculate our dimensions. To find these dimensions, we use the .shape attribute of u, calling u.shape[0] to find the dimension of the first axis, which corresponds to the N that the passed in u is utilizing. You may notice that I used u.shape[0] for both parameters, yielding reshape((u.shape[0],u.shape[0])) instead of using the u.shape[1] for the second parameter. This works only because we know that u is square, and therefore u.shape[0] and u.shape[1] will yield the same value. Therefore, there is no harm using the first index for the second parameter, however I simply chose to use the zeroth index for both. We have now successfully implemented the Au part of our equation into the function, and the next part is quite simple. As epsilon is simply a scalar, we can directly multiply the matrix that we just found by epsilon, yielding the epsilon(Au) part of the equation that we said represented the total change going from one timestep to the next. To get the actual new u for the new timestep, we can add it all to the initial u we received to get our new u. Note that we are only able to add these two values together because they are matrices of the same dimensions. Finally, we can set this whole value equal to our return value, which I also named u, and return this value.\n\nimport inspect\n%run heat_equations.ipynb\nprint(inspect.getsource(advance_time_matvecmul))\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix\n        u: N x N grid state at timestep k\n        epsilon: stability constant\n\n    Returns:\n        N x N Grid state at timestep k+1\n    \"\"\"\n    \n    #update our u to the next time step using matrix multiplication\n    u = u + epsilon * (A @ u.flatten()).reshape((u.shape[0], u.shape[0]))\n    return u\n\n\n\nFirst function is officially finished! Now looking at the parameters, we can see that epsilon will be easy to find as it is just a scalar value, u will be a bit trickier, but in the beginning it is mostly zeros, making it easier to define. On the other hand, A is a little bit trickier to create. The good news is that A does not change throughout our computations, so we just need to define it once before we start computations. We know that A is a matrix of size N2 x N2, so we can start by defining a value n to be N2 as this will be useful for the coming commands. We then create a list of numpy arrays called diagonal, of different lengths varying from n to n-N, which are all filled with ones with the exception of the first being filled with (-4). These will be used to define the diagonals in our matrix that need to be filled with 1, -1, or -4. We then call the first and third index of our list diagonals, and set ____ to equal zero. Finally, we use these diagonals to create our matrix A, which is mostly zeros with the exception of the diagonals that we had defined earlier. We then return this matrix A, concluding the implementation of this function.\n\nprint(inspect.getsource(get_A))\n\ndef get_A(N):\n    '''Defines our transition operator A given value N\n    Args:\n        N: Size of our vector u0 to be used.\n    Returns:\n        A: The NxN transition matrix that would be used for \n        a vector of size N\n    '''\n    \n    #define n to be N*N to be used as length of A\n    n = N * N\n    #Setting the diagonals to be -4 and 1 where necessary\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    #setting all other values to zero\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    #combining diagonals to create matrix A\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\n\n\nWe are now ready to check if the functions we just wrote are functioning properly! Let us go to the other file we created, jax_heat_map.ipynb, and do some setup with some more imports. For this file I imported all of the files we imported for the heat_equation.ipynb as well as importing time and pyplot from matplotlib as plt. The time package will be used to test how efficient our functions are, while the pyplot package will be used to visualize our data to ensure that we are achieving reasonable results. Next we want to ensure that we can use the function we wrote in our other file, so we can run the command %run heat_equation.ipynb. This will run the file we wrote first, allowing this new file to access all of the functions defined in the previous file heat_equations.ipynb. Next, we can decide on the values of the parameters we will use for our model. I set my epsilon to 0.2 and my N to 101 for a reasonable estimation of diffusion. Next, let us get a matrix A we can use by calling our function get_A() while passing the variable N as an argument. Finally before testing, we will create an empty list called listShow. This list is where we will store some of the information at certain time steps to get a peek into how our function is performing. Now, before we call our function, we must define an initial u0 as our starting point for our heat. A good starting point is putting one unit of heat at the midpoint. To accomplish this, we first define u to be an NxN matrix full of zeros using the command np.zeros((N,N)). To find the middle, we simply use the index u0[int(N/2),int(N/2)] and set it equal to 1.0. If we want to see how it looks, we can run the command plt.imshow(u0) and you should see a dark grid with one small, bright square in the middle. Now that we have defined all of our parameters, we are ready to start. Running the function just once will produce very minimal changes in our grid, so it is advantageous to run the model many times and check in on the results at regularly scheduled intervals. This sounds like the perfect place to implement a for loop. Let us run a variable, call it i, in range from (1, 2701), setting u0 equal to the function call of advance_time_matvecmul(A,u0,epsilon). This will run to timestep 2700, yielding enough time to see significant results. However we mentioned that we wanted to be able to check in on the progress at regularly scheduled intervals, say every 300 timesteps. To implement this, within the for loop we can write an if statement checking if i%300==0, which would imply that i is a multiple of 300. Then, within the if statement we can append both u0 and i in a list to the empty list we created just before writing this loop, listShow. I also like to print out i every time it hits a multiple of 300, to make it easier to keep track of the progress of the loop. We can now run our first iteration of our model, however note that this code block will take a long time to run. For my machine it took about a minute and a half to run. If you desire, you can time how long it takes on yours by inserting the command %%time it -r 1 -n 1 at the top of the block. This will print out how long the block of code took to run when the block is done running. While your code is running, you should be able to see a new multiple of 300 be printed out every once in a while as the variable i iterates past that value in the loop, which is a good way to keep track of the progress through the loop.\n%%timeit -r 1 -n 1\n#setting u0 to initial condition\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#using for loop to update our timestep 2700 times\nfor i in range(1, 2701):\n    #calling function to advance forward one timestep\n    u0 = advance_time_matvecmul(A, u0, epsilon)\n    if i%300 == 0:\n        #appending state every 300 steps and printing timestep for debugging\n        listShow.append([u0,i])\n        print(i)\nOutput:\n\nOur loop has finally finished running! The only issue is we do not see any results outside of the increments of 300 printed out to the screen and the excruciatingly long time it took to run that block of code, 1 minute and 39 seconds for me. Therefore, our next step is to visualize the steps our model just underwent. We remember that we stored the status of u0 at each increment of 300 in listShow. Doing some quick math we can calculate that we have nine total updates stored in this list, which we will use pyplot to display in a nice fashion. As we have nine instances, it seems reasonable to present them in a 3 x 3 grid, so let us set a variable rows and columns both equal to three. Next we are going to define a variable that will not be used until a bit later, call it img_count and set it equal to zero. We are now ready to define our display figure using pyplot by calling plt.sublots(nrows=rows, ncols=cols, figsize=(15,15)). The parameters we are passing into this function are relatively self explanatory, nrows refers to the number of rows desired, ncols refers to the number of columns desired, and figsize is how large we want the figure to be. We can set this equal to fig, axes as these will be the variables we access when plugging our information into the new grid. Finally, we can run a nested for loop to access each element of our new 3 x 3 grid. While running i in range of rows and within that j in range of columns, we call axes[i,j].imshow(listShow1[img_count][0]). This displays the image created by our stored u value in listShow in the axes indexed at [i,j]. We can see that img_count makes its long awaited appearance here, as it serves as our iterator through the list, meaning it is critical to increment it by one next to ensure that we do not print the same picture in each portion of the grid. You should see an output of a 3 x 3 grid, and in each slot there is a dark square, with a circle of light in the middle, growing bigger each time as we go from top left to bottom right. Conceptually, this makes sense as the light represents the heat diffusing throughout the square area as time passes. If you see a similar result, then we know that our first two functions are working as intended.\n#setting dimensions of image display\nrows=3\ncols = 3\n#defining variable to be used in display loop\nimg_count = 0\n#defining our display figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(15,15))\n#looping through each element in our figure, setting each to a different timestep of our model saved in list listShow\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(listShow):\n            #setting each box in display equal to unique image from list\n            axes[i, j].imshow(listShow[img_count][0])\n            #incrementing img_count to let us traverse along the list\n            img_count+=1\n\nNow that our first two functions are up and running, we can start working on our next function, get_sparse_A(). The purpose of this function is simply to take in a dimension N and return the sparse version of the A matrix corresponding to the N. Luckily, we have already done half of the work in our previous function get_A(), which we can call directly while passing it the parameter N. This will create the A matrix that we intend to convert into a sparse matrix. The jax package holds an experimental sparse matrix support that we will be using for this purpose. The exact format we will use is called the batch coordinate (BCOO) format, which will allow us to use less space to store this matrix, which will in turn drastically decrease the time required for the matrix multiplication. In order to convert this A matrix into its sparse form, we run the command sparse.BCOO.fromdense(A). We call sparse as it is part of the sparse package, BCOO is the format in which we wish to convert the matrix to, and fromdense signifies that we wish to go from a normal or ‘dense’ matrix, to a sparse matrix. Now we assign that to our return value A_sp_matrix, and return that value, completing the purpose of this function.\n\nprint(inspect.getsource(get_sparse_A))\n\ndef get_sparse_A(N):\n    '''Returns a sparse form of our transition matrix A\n    Args:\n        N: Size of our vector u0 to be used\n    Returns:\n        A_sp_matrix: The sparse form of the NxN transition matrix \n        that would be used for a vector of size N \n    '''\n    \n    #get the matrix A corressponding to the passed value N\n    A = get_A(N)\n    #find sparse version of matrix A and set it to our return value \n    A_sp_matrix = sparse.BCOO.fromdense(A)\n    return A_sp_matrix\n\n\n\nWe now want to double check that this function is running properly, so we will traverse back to jax_heat_map.ipynb to run a similar chunk of code that we ran previously, with a few key differences. First, instead of passing A to our advance_time_matvecmul() function, we want to ensure it is able to handle a sparse matrix in the hopes that it will decrease the time needed for computations. In order to get such a sparse matrix, we call our new function get_sparse_A(), while passing N as an argument. I set this equal to a variable named sp_A so that I knew this was the sparse version of my A matrix. Then, I initialized a new list called listShow1, setting it equal to an empty list. Next, we want to do the same process we did to check our first two functions, except this time we will pass in sp_A to advance_time_matvecmul() as well as applying the jit function to it. The jit function will use the jax just in time compilation feature which will drastically improve the performance of the function. When running this code block, we can see how much this improves the speed, taking the block 1.7 seconds to finish as opposed to over a minute for the previous attempt. Again using a similar process to above, we will display our data in the exact same way, except we will be getting our display information from listShow1 instead of listShow. Our output should be similar to the output we got previously.\n%%timeit -r 1 -n 1\n#resetting u0 to initial condition\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#looping to increase timestep a total of 2700 times\nfor t in range(1, 2701):\n    #calling jitted version of function to advance timestep\n    #note that the matrix passed in is a sparse matrix\n    u0 = jit(advance_time_matvecmul)(sp_A, u0, epsilon)\n    if t%300 == 0:\n        #appending timestep information once every 300 steps, printing for debugging purposes\n        print(t)\n        listShow1.append([u0,t])\nOutput:\n\n#defining dimensions of our display figure\nrows=3\ncols = 3\n#resetting variable to be used in display loop\nimg_count = 0\n#defining our display figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(15,15))\n#looping through each element in our figure, setting each to a different timestep of our model, saved in list listShow1\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(listShow1):\n            #sets each box in display to different image in listShow1\n            axes[i, j].imshow(listShow1[img_count][0])\n            #increment img_count to traverse along the list\n            img_count+=1\n\nWe are now prepared to implement another method, providing us with an alternate way to run our model without using matrix multiplication. Instead, we will use vectorized array operations to progress our model, made possible by the numpy passage. We have the equation that the update discrete update time is:\n\nTherefore we need to find a way to update each point so as to abide by this equation. For me it helped to visualize it in two separate updates, a vertical and horizontal one. Looking at the horizontal changes, we see that for each value in the matrix at time t+1, is created in part by adding the elements directly to the left and right from the matrix at time t. As you may be considering already, we run into an issue with the values at the borders in which there is no value to either the right or the left. To deal with this, we will create an array of zeros of size (N+2)x(N+2), and place our current grid state at time u into the middle of the matrix. This will give us a bit of leeway in our computations as these outer values will not affect the inner values as they are zeroes and it does not matter computationally what happens to them does not matter as we will get rid of them before returning our updated grid state u_new. Starting from the beginning, we have to get what value to use for N as we are only passed in u and epsilon. To do this we will again extract N using the shape of the grid state u passed into the function, accomplished by setting m,N to u.shape. Now that we have acquired our value for N, we can define our (N+2)x(N+2) matrix full of zeros by again using the function np.zeros((N+2,N+2)). To set the middle to be equal to u, we use indexing and set the middle region, indexed by [1:-1,1:-1], equal to the grid state u. Now that we have our matrix u with a surrounding padding of zeros, we can begin our calculations. We first will find our changes in the x-direction using the update equation stated earlier and numpy’s .roll() method. The .roll() method rolls each element along a given axis, with values rolling past the last position being sent back to the first position. We can use this to define the change between each iteration. It helped me to split it into two changes, one along the x-axis and the other along the y-axis. Looking at the x-axis, for each updated element we need to add the element directly to the left and right of it, which we can accomplish by using an np.roll() both left and right. We do this by setting the axis equal to zero, as that corresponds to the x-axis, and first setting the shift to one, as that moves us one element to the right. Next, we call np.roll() again and set the shift to -1, representing a shift to the left. Now we can do the same thing for the y-axis, the only difference being we are setting the axis in our roll functions equal to 1 as that corresponds to the y-axis. Now we have taken care of almost all of the changes found in our discrete time equation, but we are missing the 4u term. To account for this, I simply subtracted 2u from each equation to combine for a total of (-4u), however you could do this at a later stage if desired. Now that we have determined what the change is to be between timepoints, we multiply by epsilon and add the u passed into the function as we did in our previous advance_time_matvecmul() function, setting it equal to a matrix named finU. We may be tempted to stop here, however we are missing a key factor: the matrix we have created remains a (N+2)x(N+2) matrix, when we want to return a matrix of size N x N. Luckily, we have set it up so that the outer ring of values are to be thrown away, as we initially introduced them within the function. To accomplish this, we set our return matrix, u_new, equal to the center portion of finU using the indices[1:-1,1:-1] before returning this new matrix.\n\nprint(inspect.getsource(advance_time_numpy))\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"Advances simulation by one timestep using functions from numpy\n    Args:\n        u: NxN grid state at timestep k\n        epsilon: stability constant\n        \n    Returns: N x N Grid state at timestep k+1\n    \"\"\"\n    #get N so we know the size of matrix we are working with \n    m,N = u.shape\n    #create new matrix of size with two extra rows and columns\n    newU = np.zeros((N+2,N+2,),dtype='float64')\n    #set the center of new matrix equal to u, meaning ring of zeros around passed matrix u\n    newU[1:-1,1:-1] = u\n    #implement changes in x direction\n    u_xx = np.roll(newU, shift=1, axis=0) - 2 * newU + np.roll(newU, shift=-1, axis=0)\n    #implement changes in y direction\n    u_yy = np.roll(newU, shift=1, axis=1) - 2 * newU + np.roll(newU, shift=-1, axis=1)\n    #apply changes and set it equal to a new matrix\n    finU = newU + epsilon * (u_xx + u_yy)\n    #eliminate outer ring of values, allowing the heat to escape, setting equal to return value\n    u_new = finU[1:-1,1:-1]\n    return u_new\n\n\n\nTo check that this function is running correctly, we can repeat the same debugging process we have done twice now in jax_heat_map.ipynb: create a new empty list, and run our loops. However this time, we will call the new function advance_time_numpy() and only pass the parameters u and epsilon as this function only takes these two parameters. You should notice another increase in speed as mine took 520 ms to run the code. Again, the output should appear very similar if not identical to the outputs from our previous attempts using the other functions. Note, the function advance_time_numpy() is not to be jitted as advance_time_matvecmul() was.\n%%timeit -r 1 -n 1\n#resetting u0 to initial conditions\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#looping to increase timestep a total of 2700 times \nfor t in range(1, 2701):\n    #calling numpy function to advance timestep\n    u0 = advance_time_numpy(u0, epsilon)\n    if t%300==0:\n        #appending timestate information once every 300 steps, printing for debugging purposes\n        newList.append([u0,t])\n        print(t)\nOutput:\n\n#setting the dimensions for our display figure\nrows=3\ncols = 3\n#resetting variable used in display loop\nimg_count = 0\n#defining our display figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8,8))\n#looping to fill our display figure\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(newList):\n            #setting each box in display equal to unique image from list newList\n            axes[i, j].imshow(newList[img_count][0])\n            #incrementing img_count to traverse to next list element\n            img_count+=1\n\nFinally, we have come to our last function, advance_time_jax(). In this function, we wish to implement a similar method to advance_time_numpy(), however as we plan to jit this function, we have to be careful in how we do so. Much of the setup is the same as the numpy function as we will use u.shape() to get our value for N and will then create a new matrix of size (N+2)x(N+2) full of zeros called newU. We again wish to fill the middle of this matrix with the matrix that we were passed in, however we cannot change individual indices due to restrictions for jax, therefore we will be creating lots of new matrices. Therefore, instead of directly reassigning values for the central section of our matrix newU, we will use the .add function to add u to just our central section by calling the function .at[1:-1,1:-1], effectively placing u in the middle as we are simply adding u to a bunch of zeros. After assigning this altered matrix back to newU, we can do the same process as we did in numpy to define our changes in the x and y directions, however instead of calling np.roll(), we will be calling jnp.roll() to call the jax version of numpy. We can then apply the changes, assigning it to a new matrix finU, in the same way as we did in numpy as finU = newU + epsilon*(u_xx+u_yy). Now, we can select just the center values, setting it equal to the new matrix we will be returning, u_new, and we are finished with our final method.\n\nprint(inspect.getsource(advance_time_jax))\n\ndef advance_time_jax(u, epsilon):\n    \"\"\"Advances simulation by one timestep using jax without using\n        matrix multiplication routines.\n    Args:\n        u: N x N grid state at timestep k\n        epsilon: stability constant\n        \n    Returns: N x N Grid state at timestep k+1\n    \"\"\"\n    #get N so that we know what size of matrix we are working with\n    m,N = u.shape\n    #create new matrix with two extra rows and columns\n    newU = jnp.zeros((N+2,N+2))\n    #set the center of the new matrix equal to the passed matrix u\n    newU = newU.at[1:-1,1:-1].add(u)\n    #define the changes to be implemented in the x direction\n    u_xx = jnp.roll(newU, shift=1, axis=0) - 2 * newU + jnp.roll(newU, shift=-1, axis=0)\n    #define the changes to be implemented in the y direction\n    u_yy = jnp.roll(newU, shift=1, axis=1) - 2 * newU + jnp.roll(newU, shift=-1, axis=1)\n    #implement the changes into a new matrix\n    finU = newU + epsilon * (u_xx + u_yy)\n    #setting the return value to the matrix with only desired values\n    u_new = finU[1:-1,1:-1]\n\n    return u_new\n\n\n\nTo check that we have created another functioning method, we repeat the same debugging process as we did for advance_time_numpy(), except we create a different list and call the advance_time_jax() function while making sure to jit the function as we call it. This function should be very fast, even faster than our previous function, as mine took 291 ms to run the code. If the output appears identical to our previous iterations then we have completed all of our methods successfully.\n%%timeit -r 1 -n 1\n#resetting u0 to initial conditions\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#looping to increase timestep a total of 2700 times\nfor t in range(1, 2701):\n    #using jax function to advance timestep by one\n    u0 = jit(advance_time_jax)(u0, epsilon)\n    if t%300 == 0:\n        #once every 300 steps append timestep information to list, printing step for debugging purposes\n        newList1.append([u0,t])\n        print(t)\nOutput:\n\n#defining dimensions of display\nrows=3\ncols = 3\n#resetting variable used in display loop\nimg_count = 0\n#defining our figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8,8))\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(newList1):\n            #filling each box with image from information in newList1\n            axes[i, j].imshow(newList1[img_count][0])\n            #incrementing to allow for traversal along list\n            img_count+=1"
  },
  {
    "objectID": "posts/bruinPage/index.html",
    "href": "posts/bruinPage/index.html",
    "title": "Analysis and Recommendations of Web Scraped Movie Data",
    "section": "",
    "text": "In this blog post, I’m going to create a web scraper that will allow us to recommend new movies based on shared actors with your favorite movie.\nThe first thing we are going to do is navigate to the website called TMDB, found at the URL https://www.themoviedb.org/ . We can now pick our favorite movie that will be the basis of our recommendations, mine is Harry Potter and the Philosopher’s Stone. Next, I navigated to the main movie page found at: https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone This URL is important to save for later as it will be the starting point for our spider. Now we can start to create our spider. The first step is to type the following into the terminal:\nconda activate PIC16B-24W\nscrapy startproject TMDB_scraper\ncd TMDB_scraper\nThis command will activate the PIC16B-24W environment that we installed previously, create a scrapy project with the name TMDB_scraper on your computer, and then change the directory of your terminal to your newly created project. As we navigate to the TMDB_scraper folder, we see that there are various files within the project, however first we want to navigate to the file titled ‘settings.py’, and add the following line:\n    CLOSESPIDER_PAGECOUNT = 20\nThis will limit the number of pages our spider will visit initially, limiting the amount of data it will acquire when we are constructing and debugging. Additionally, I wrote the line:\nUSER_AGENT = 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'\nThis line helps to minimize the chance that the website identifies your spider as a bot and tries to block the web scraping process. Finally, it is time to begin writing our spider. Inside of our project folder, navigate into the spiders directory and create a new file titled ‘tmdb_spider.py’, and add the following chunk of code to the file:\nimport scrapy\n\n\nclass TmdbSpider(scrapy.Spider):\n\n    name = 'tmdb_spider'\n    \n    def __init__(self, subdir=None, *args, **kwargs):\n    \n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\nThis code chunk will allow us to run the spider for our movie of choice from the terminal by giving the subdirectory on the TMDB website as our extra argument. Now that we have a working spider, it is time to implement our three parsing methods: parse(self, response), parse_full_credits(self, response), and parse_actor_page(self, response).\nLet’s start with the parse(self, response) function. The role of this function is to navigate from our main movie page to the ‘Full Cast and Crew’ page. If we go back to our main movie page, and navigate to the ‘Full Cast and Crew’ page, we can see that the only change in our URL is there is now a ‘/cast’ at the end. That tells us, all we need to do to get to our cast page is to add ‘/cast’ to the end of our current URL, and send our spider to the page found by our new URL. As we can see in the function below, we define our new URL to be called ‘full_credits_url’ which is created by taking ‘response.url’, the URL of the page we’re on, and adding the string ‘/cast’ to the end. As we now have the URL for the page we want to navigate to, we yield a scrapy.Request to send our spider to the cast page, passing our new ‘full_credits_url’ as the URL parameter, and setting the callback to the parse_full_credits() function as we will now navigate to the full credits page.\ndef parse(self, response):\n\n        '''\n        This function takes us from the main movie page to the cast and credits page yielding the url of the full credit page to be parsed by the parse_full_credits\n        '''\n        \n        #modifies url in order to navigate to the cast page\n        \n        full_credits_url = response.url + '/cast'\n        \n        #sends spider to the full credit page\n        \n        yield scrapy.Request(url=full_credits_url, callback=self.parse_full_credits)\nNow that we have made it onto the full cast and credits page, we will work with the parse_full_credits(self, response) function that was called as we navigated to this page. The goal of this function is to find all the actors who played a role in the movie and send our spider to their individual pages to be parsed by our final function parse_actor_page(). Last time we were able to navigate to the cast page by simply adding ‘/cast’, however as each actor has their own distinct name and page, we will not be able to hardcode the new URL. In fact if you click on the first actor or actress in the list, in my case Daniel Radcliffe, we see that the URL for their individual page contains a seemingly arbitrary number followed by their name. In order to find the extension for each actor, let us navigate back to the full cast and credits page. By right clicking on the top actor or actress’s name, followed by clicking inspect, we can see where their name is stored in the HTML file. More importantly, just before where their name is stored in text, we see something similar to ‘ Daniel Radcliffe’. Should we navigate back to Mr. Radcliffe’s page, we can see that the the element defined as ‘href’ is the same as the URL extension for the page, after the ‘https://www.themoviedb.org/’ that all pages on the TMDB site begin with. Clearly this is critical information as it will allow us to navigate to the actor or actress’s page using their URL extension. Now, we simply need to find a way to access this information for all of the actors. As we go back to the cast and credits page and look at the line where the first name was stored, we can traverse backwards to the line starting with “&lt;li data-order=”0” data-credit-id=” and then up again to the line reading ‘&lt;ol class = “people credits”&gt;’. It is important to note the information of all the cast members, including their names and the ‘href’ URL extensions we are trying to extract are all located under this ol class. We want to access this class from the HTML file in order to use it in our function, which we will be able to accomplish using css selectors. By taking a look at the first line of code, we can see that in the selector, we start in the overarching ol class, before specifying to travel down through the li class and finally asking for the attribute ‘href’ located within a. One thing to note about this line is the ‘:not(.crew)’ following the ol class. This effectively tells the program that all we do not want the attributes of any of the crew members, but only the attributes of the actors. Additionally, the .extract() command at the end of the line effectively gathers the information from the location we specified in the selector, allowing us to assign it to our variable actor_selectors. This command returns a list of the URL extensions for every actor in the movie and stores it in the actor_selectors variable. Now that we have the URL extensions, we can finish this function in a similar manner to the initial parse() function by creating new URLs for the spider to follow. As we observed before, every actor page starts with ‘https://www.themoviedb.org/’, and is followed by a tail unique to each actor which we have stored in the actor_selectors list. Now, to send our spider to each actor page, we simply write a for loop that iterates through all of the actor extensions in our actor_selectors list, add the extension to the generic URL started mentioned above, and again send the spider to the new page addressed by our new URL saved as actor_page_url. Our yield scrapy.Request() is slightly different than the one we used in the previous function as instead of calling parse_full_credits(), we are going to call parse_actor_page() as the spider is now traveling to an individual actor page.\n def parse_full_credits(self, response):\n \n        '''\n        This function navigates from the response's full credits page to each actor's individual page to be parsed in the parse_actor_page() function.\n        '''\n        \n        #creates list of cast members, excluding the crew members\n        \n        actor_selectors = response.css('ol.people.credits:not(.crew) li div.info a::attr(href)').extract()\n        \n        #for loop iterates over actor list sending spider to each actor page\n        \n        for actor_ in actor_selectors:\n        \n            actor_page_url = 'https://www.themoviedb.org'+actor_\n            \n            yield scrapy.Request(url=actor_page_url, callback=self.parse_actor_page)\nWe have now reached our third and final parsing function, parse_actor_page(self, response). The goal of this function is to identify all the movies in which the individual played an acting role and yield dictionaries that contain the individual’s name with the title of the movie they played a role in. The first thing we must do is identify the name of the actor or actress whose page we are on. This will be a similar process to finding the actor page references in the previous function, however this time there is only one piece of data we wish to extract, making it even simpler. Let us continue with our Daniel Radcliffe example from earlier by navigating back to his actor page. By highlighting his name at the top of the page and then clicking on the inspect option, we can again see where his name is stored in the HTML file associated with this page. We can see it is located as an attribute under a class titled ‘h2 class=”title”&gt;’ which we will again be able to access via css selectors. As we can see from the first line of code below, in the css selector we start at the h2 title class and then traverse to the ‘a’ section in which the name is located. Different from last time, we add the command ‘::text’ afterwards to tell the program we want the text stored at this location as opposed to the href attribute which is what we were looking for in the previous function. It is also important to note that here we are using .extract_first() instead of .extract() as we want the name itself as a string instead of a list containing the name, which is accomplished by .extract_first() which extracts the first element of the list to be returned while .extract() would grab the entire list. The .strip() at the end of the line simply ensures that there is no whitespace before or after the name to keep everything neat and consistent. We now have the name of the individual who the page belongs to stored under the variable actor_name, meaning that now we only need to find the names of the movies in which they played an acting role. We will now again implement a similar method to extract the titles of the movies the actor played a role in. If we highlight the title of the first movie or show under the ‘Acting’ section and check where it is located in the HTML file, we find it is under one of many sections labeled ’\n\n’ which are all under a table class titled ‘credits list’. While we could try and simply use the css selectors to try and locate this class as before, we must notice that there are two other classes with the same title, which would clearly make it somewhat tricky for the program to decipher exactly which one we are trying to access. Taking a closer look at these three classes, we can observe an h3 line above each one which are identical except for one word in each, the different words being ‘Acting’, ‘Production’, and ‘Crew’. Clearly we want to access the one referring to the acting roles, as we are not concerned with production and crew roles, however we need to find a way to access the correct table under acting. By taking another glance at the HTML file, we can see that the three classes of interest are all located within a div class titled ‘credits_list’. We can take advantage of this by creating a list of all the h3 terms under this list via the command defining datCred. Now that we have the list, we can simply search for which h3 contains the word ‘Acting’ to find exactly which table we want by using a for loop to iterate through each h3 element in datCred. We check for acting by checking if ‘Acting’ is in the text of the h3 element, as found in the condition of the if statement within the for loop. Now that we have identified which h3 term we want to follow, we will take advantage of xpath, another kind of selector, which has a useful function called ‘following-sibling’. This specifier tells the selector to follow a sibling class, a class with the same parent and on the same level as the initially specified node, and we have then included the xpath to ‘table[1]’ in which the tr classes containing the movie names are located, saving it to the variable txt. We then use the Selector() function to make it so that we can access just the data under the location we specified as opposed to the entire response that scrapy has found. It is worth noting that to run this command we must import the selector library from scrapy.Selector at the top of the page, with the line of code shown just below:\nfrom scrapy.selector import Selector\nFinally, we use the subset of the response to extract the movie titles for the actor. This process is shown in the final for loop. We call all elements in ‘tablePick.css(‘table.credit_group tr’)’ to access all of the tr classes individually, and then set the movOrTvName to the text under the class ‘role’ and within the ‘tooltip’ class and as the bdi attribute in the HTML file. Finally, we yield a dictionary with the actor name that we found in the beginning of the function, and the movie name that we just found. This will loop through all of the movies that the actor played a character in, resulting in all of their movies being represented in their own dictionaries to be saved in a .csv file we will create next.\ndef parse_actor_page(self, response):\n\n        '''\n        This function parses the actor page, extracting both the actor name and the movies/shows they were in, yielding the dictionaries with the actor name and the movies they appear in.\n        '''\n        \n        #extracts actor name from page\n        \n        actor_name = response.css('h2.title a::text').extract_first().strip()\n        \n        #list of data under actor acting appearances\n        \n        datCred = response.css('div.credits_list h3')\n        \n        #filtering to just acting roles\n        \n        for h3 in datCred:\n        \n            if 'Acting' in h3.xpath('./text()').get():\n            \n                txt = h3.xpath('following-sibling::table[1]').get()\n                \n                break\n                \n        #making tablePick a selector used to follow to movie data\n        \n        tablePick = Selector(text = txt)\n        \n        #extract and yield movie/show name with the actor name\n        \n        for cred in tablePick.css('table.credit_group tr'):\n        \n            movOrTvName = cred.css('td.role a.tooltip bdi::text').get().strip()\n            \n            yield{'actor': actor_name, 'movie_or_TV_name' : movOrTvName}\nNow that we have finished writing our spider, we are ready to run it in order to scrape our desired data off of the TMDB website. The first thing we need to do is go back into the settings.py file and comment out the page count limit we implemented just before creating our spider to allow our spider to scrape all of the pages it is sent to. We can now go back to the terminal and run the following command:\nscrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\nNote that the command is all one on the same line. This command will tell our spider to crawl on the website for the first Harry Potter movie as given by the subdirectory, and will write all of the results in a file named ‘results.csv’. If we go back into the project folder, we can open the file we just created and we will see dictionaries represented by a table with one column containing the actor names and the other column containing the titles of the movies that respective actor appeared in. This is where we will access the results our spider was able to produce. We can now use this data to create our recommendations.\nOur first step in creating our recommendations is importing our necessary packages and reading in the data we just acquired and saved into results.csv, which can be done via the following code:\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#reading in the data we scraped using our spider\ndf = pd.read_csv('/Users/jakebrowning/Desktop/PIC16B/TMDB_scraper/results.csv')\n#using for loop to create a counting function for how many actors are in each movie\nmovDict = {}\nfor el in df1:\n    if el in movDict.keys():\n        movDict[el] = movDict[el]+1\n    else:\n        movDict[el] = 1\n\n#adjusting my dictionaries for the pandas dataframe\nsortedMovDict = sorted(movDict.items(), key=lambda x:x[1], reverse=True)\nconvertedMovDict = dict(sortedMovDict)\n\n#putting the counted dictionary into a pandas dataframe and displaying the dataframe\ndfList = pd.DataFrame(list(convertedMovDict.items()),columns=['Movie Name','Number of Shared Actors'])\ndfList\nWe can see this yields a list of movies containing shared actors, ordered from most shared actors to least shared actors with our original movie.\n\n\n#creating lists of the top twenty movies and their numbert of actors\nmovN = []\nnumAct = []\ni=0\nwhile i &lt; 20:\n    movN.append(dfList['Movie Name'][i])\n    numAct.append(dfList['Number of Shared Actors'][i])\n    i = 1+i\n\n#changing order of list to be better displayed in the graph\nmovN.reverse()\nnumAct.reverse()\n\n#creating bar chart with top twenty movie recommendations, displaying how many shared actors in each movie\nmyChart = plt.barh(movN, numAct)\nplt.bar_label(myChart, labels=numAct, label_type=\"edge\")\nplt.title('Top Twenty Movie Recommendations')\nplt.xlabel('Number of Shared Actors')\nplt.ylabel('Movie Title')\nplt.show()\nThis leaves us with our top twenty recommendations, shown in decreasing order by the bar chart displayed below."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "16bhwblog",
    "section": "",
    "text": "Imports\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW 4: Heat diffusion with Jax\n\n\n\n\n\n\nweek 6\n\n\n\n\n\n\n\n\n\nFeb 22, 2024\n\n\nJake Browning\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 3: Flask\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\nJake Browning\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 11, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis and Recommendations of Web Scraped Movie Data\n\n\n\n\n\n\nweek 6\n\n\n\n\n\n\n\n\n\nFeb 11, 2024\n\n\nJake Browning\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 8, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]