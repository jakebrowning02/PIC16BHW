[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/flaskHW/index.html",
    "href": "posts/flaskHW/index.html",
    "title": "Homework 3: Flask",
    "section": "",
    "text": "https://github.com/jakebrowning02/PICHHW3 https://jakebrowning02.github.io/PIC16BHW/posts/flaskHW/\nWe will start the tutorial with the init.py file. The first function we see in this file is create_app(). The function effectively the creation of the app. As we can see, in the first line, we will set the app to be an instance of the Flask class that we imported at the top of the page. Next we begin to configure the app by defining where the database is to be located, by mapping the database to the ‘flaskBlog.sqlite’ file. If you are wishing to use a different file name for your database, that is fine, but just be sure to use that file name here instead of the one that I used. It is important to note, that for this we must import os at the top of the page. The function os.path.join shows the computer how to reach the file we have specified. Continuing downward, we see a hello() function. This function is not critical to this project, but is useful in checking that the app is working correctly and also happens to be an easier wsay to explain how these functions work. Above the function we see the command ‘@app.route(’/hello’)’ which is critical to this function. This ties the url route ‘/hello’ to this function, a practice we will use pervasively throughout this project. This page simply prints out ‘Hello, World!’, but other pages will have more complex applications. The following commands are all imports that we will revisit later after we have defined the functions that they are referring to. Let’s move over to the db.py file. This file is responsible for defining most of the basic commands necessary for setting up our database. The first thing we want to do is to import sqlite3. This allows us to make an sqlite3 database on this page. We will also import click for a later function, but more importantly, we import both current_app and g from the flask library. g is a special object that is able to be accessed by multiple functions, which is also unique for each request. Similarly, current_app is another special object that points to the Flask application handling the request. We will ensure that current_app will be able to be used by importing this file into the other .py files. The first function we see is get_db(). We first want to check that there is no database currently in our special instance g. If there is not, logically we want to begin to access the database. We define the database connection by creating an attribute db of g, and setting it to sqlite3.connect(), effectively making it a cursor we can use to search the database in later functions. We then return this attribute so that when we import it into other files, we can effectively use this as our cursor. The next function close_db() is rather self explanatory. We need a way to close the connection to the database if the database is open. We check if it is open by writing the if statement ‘if db is not None:’. This way, we only attempt to close the connection if it exists, which we do within the if statement by calling db.close(). We now come across our function that is called when we are intiating the database, init_db(). Using the function we just defined, we call get_db() to create a cursor, and using that we open the schematic that we write for the database, defining the tables, rows, columns, and titles to be held within the database. The next function gives us a way to call the function we just created. We call @click.command(‘init-db’) so that we can call the function using a command line command. Now, when we call this function via the command, we can see that it simply calls the init_db() function and recieve a message letting us know that we have successfully initialized the database. Finally, we come to the init_app() function. This function will be used to ensure that the cursor is closed when it needs to be. In order to ensure that the cursor is closed each time after returning a response, we will use the function teardown_appcontext(). This calls whatever function is within the parentheses whenever a response is returned, so we choose to call close_db() whenever a response is returned. Finally, we want to travel back to init.py and look at what we imported from this page. By importing db.init_app(app), we allow ourselves to initiate the database within the init.py file. Let us now take a look at our last .py file, blog.py. This file will contain most of what we see on the web app. We will import several useful methods from flask up top to be able to run our code. Taking a look at the first function index(), we see it appears to have a similar formate to the hello() function we saw before. Using the @bp.route(‘/’), we define the URL extension to be the backslash to access this page. First thing we do in this function is define db to be the cursor we get from the get_db() function we created in the previous page. Now, we will use this cursor to access the database. We now select both the author and body attributes from every post in the database, and set this list to be the list posts. This will be used in the html to show all of the posts that are contained within our database. This is useful for debugging and being able to view the database in a user friendly manner. Now we reach the return line of this function by calling render_template() we tell the computer to run the html file template we have created for this page called ‘index.html’. In my case, this file is contained within a blog folder, hence the ‘/blog’ before the ‘index.html’. We also choose to pass the posts list to the template as it is used to display the posts on this page. Continuing on, we get to the function used to insert new messages into the database. We see the function is associated with the URL extension ‘/submit’, however this time we also define the methods(‘GET’, ‘POST’), as any user request will be considered a ‘POST’. We check to make sure that this is the case via the if statement at the beginning of the function. Now we need to get input from the user so that we can input their name and their message. We do so by using the request.form[] function, allowing us to use the input to define the variables. We then check that the boxes have been filled, and send an error if they have not been. If everything is working well, we then use the get_db() function to access the cursor again and use it to insert the new message with its author into the database. We ensure to call db.commit() to save the new information into the database and call for a redirect. This function sends us back to the main page by calling the index function in the blog.py file, or in other words the function above this one. We also make sure to render the template for this page so that the html file we write will appear on this page. The random_messages function again uses the cursor we acquire from get_db(). We then use a special command for the cursor ‘RANDOM()’ to select the rows from the database in a random order. We use the variable n to determine how many rows are to be selected, and then set this to the list messages to be returned by this function. The view function is associated with its own URL and is the page used to determine how many random posts the user withes to see. We use request.form.get() to take in the user input. Then again, assuming no errors, we call random_messages function with the user inputted amount of function and pass it to our final function randomview(). This final function is associated with its own URL and gets random messages from the random_messages function. We call int(request.args.get(‘num_messages’)) to get the amount of messages desired by the user, a value passed by the previous page. Finally, we will take a look at our template for the new post page. First, we extend ‘base.html’ so that we can keep what we coded in that. We now define our header under the {%block header%} and set the block title to ‘New Messages’. Next, we get to the block content. We create a label titled ‘Author’ which is used for our input. This title is placed with the input text box that sends its input to the value request.form[‘author’] which we use to input the value into the database. We then do the same for the message, however this time we define a textarea to create a bigger box for the user to input their message. Finally, we create a submit button that says ‘Submit message’ for the user to click after they input their desired information."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/HW5/index.html",
    "href": "posts/HW5/index.html",
    "title": "HW 5: Image Classification with Keras",
    "section": "",
    "text": "import os\nfrom keras import utils\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nThis block is where we will begin our imports to be used for this project. We then change the backend of keras to be tensorflow as it will allow for our image augmentation layers to run faster.\n\nimport keras\nfrom keras import layers\n\nWe have another import block in which we import keras and layers from keras. It is important that keras is imported after we change the backend to tensorflow, as that cannot be changed once keras has been imported.\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    #40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True, #Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nDownloading and preparing dataset 786.67 MiB (download: 786.67 MiB, generated: 1.04 GiB, total: 1.81 GiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\nDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\nNumber of training samples: 9305\nNumber of validation samples: 2326\nNumber of test samples: 2326\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\n\n\nThis block is used to access our data, as well as organizing it into datasets that will be used later. As we define our dataset names in the beginning as train_ds, validation_ds, and test_ds. We then call tfds.load, which loads datasets from the tensorflow_datasets library, which we then specify to be the “cats_vs_dogs” dataset. We then define splits for how much data will be implemented into each dataset. As you can see above, forty percent is dedicated to training, while only ten percent are allocated to both the validation and test datasets. Finally, we print out how many samples are in each dataset by calling the cardinality of each dataset. As expected, the number of training samples is approximately four times larger than that of the validation or testing datasets, which are themselves equal in size.\n\nresize_fn = keras.layers.Resizing(150,150)\n\ntrain_ds = train_ds.map(lambda x,y: (resize_fn(x),y))\nvalidation_ds = validation_ds.map(lambda x,y : (resize_fn(x),y))\ntest_ds = test_ds.map(lambda x,y:(resize_fn(x), y))\n\nWe now clean up our data a bit by creating a constant size for all samples. We can see that resize_fn calls a keras layer that resizes its input to be of size 150 x 150. We then use this layer to create lambda functions to be applied to all three of our datasets. We can now be sure of the dimensions of all of our samples in each of our datasets.\n\nfrom tensorflow import data as tf_data\nfrom tensorflow.keras.optimizers import Adam\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nThis block is a bit technical. We import tf_data to be used in this block, as well as an optimizer called Adam that we will not use until later. The batch_size variable we define determines how many data points are gathered from the directory at once."
  },
  {
    "objectID": "posts/HW5/index.html#imports",
    "href": "posts/HW5/index.html#imports",
    "title": "HW 5: Image Classification with Keras",
    "section": "",
    "text": "import os\nfrom keras import utils\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nThis block is where we will begin our imports to be used for this project. We then change the backend of keras to be tensorflow as it will allow for our image augmentation layers to run faster.\n\nimport keras\nfrom keras import layers\n\nWe have another import block in which we import keras and layers from keras. It is important that keras is imported after we change the backend to tensorflow, as that cannot be changed once keras has been imported.\n\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    #40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True, #Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\n\nDownloading and preparing dataset 786.67 MiB (download: 786.67 MiB, generated: 1.04 GiB, total: 1.81 GiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\nDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\nNumber of training samples: 9305\nNumber of validation samples: 2326\nNumber of test samples: 2326\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWARNING:absl:1738 images were corrupted and were skipped\n\n\n\n\n\nThis block is used to access our data, as well as organizing it into datasets that will be used later. As we define our dataset names in the beginning as train_ds, validation_ds, and test_ds. We then call tfds.load, which loads datasets from the tensorflow_datasets library, which we then specify to be the “cats_vs_dogs” dataset. We then define splits for how much data will be implemented into each dataset. As you can see above, forty percent is dedicated to training, while only ten percent are allocated to both the validation and test datasets. Finally, we print out how many samples are in each dataset by calling the cardinality of each dataset. As expected, the number of training samples is approximately four times larger than that of the validation or testing datasets, which are themselves equal in size.\n\nresize_fn = keras.layers.Resizing(150,150)\n\ntrain_ds = train_ds.map(lambda x,y: (resize_fn(x),y))\nvalidation_ds = validation_ds.map(lambda x,y : (resize_fn(x),y))\ntest_ds = test_ds.map(lambda x,y:(resize_fn(x), y))\n\nWe now clean up our data a bit by creating a constant size for all samples. We can see that resize_fn calls a keras layer that resizes its input to be of size 150 x 150. We then use this layer to create lambda functions to be applied to all three of our datasets. We can now be sure of the dimensions of all of our samples in each of our datasets.\n\nfrom tensorflow import data as tf_data\nfrom tensorflow.keras.optimizers import Adam\nbatch_size = 64\n\ntrain_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\nvalidation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\ntest_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n\nThis block is a bit technical. We import tf_data to be used in this block, as well as an optimizer called Adam that we will not use until later. The batch_size variable we define determines how many data points are gathered from the directory at once."
  },
  {
    "objectID": "posts/HW5/index.html#visualization",
    "href": "posts/HW5/index.html#visualization",
    "title": "HW 5: Image Classification with Keras",
    "section": "Visualization",
    "text": "Visualization\n\ndef twoRowVis():\n    plt.figure(figsize=(10, 10))\n    for images, labels in train_ds.take(1):\n        dogNum = 0\n        catNum = 0\n\n        for i in range(32):\n            if labels[i].numpy() == 1 and dogNum &lt; 3:\n                ax = plt.subplot(2, 3, dogNum + 1)\n                plt.imshow(images[i].numpy().astype(\"uint8\"))\n                plt.title(f\"Label: {labels[i].numpy()}\")\n                plt.axis(\"off\")\n                dogNum += 1\n\n            elif labels[i].numpy() == 0 and catNum &lt; 3:\n                ax = plt.subplot(2, 3, 3 + catNum + 1)\n                plt.imshow(images[i].numpy().astype(\"uint8\"))\n                plt.title(f\"Label: {labels[i].numpy()}\")\n                plt.axis(\"off\")\n                catNum += 1\n\n            if dogNum == 3 and catNum == 3:\n                break\n\n    plt.show()\n    return\n\n\n\nAbove we have created a function for visualizing some of our images. We first set the size of the images by setting our figure size to (10,10). Now we need to access our images to be able to fill our plot. The method used to do this is take(1), which will retrieve one batch of images with labels, which we defined to be of size 64 in the previous code block. We will begin a for loop using these labels and images by calling for images and labels returned by the take method we call upon train_ds. It is critical to note that images containing dogs are labeled with a 1 while images with cats are labeled with a 0. Now that we have accessed our images, we wish to display a row of three images of dogs, followed by a row of three images with cats in them. In order to keep track of how many images of each have been displayed, we will create two variables titled numCats and numDogs respectively. We can now loop through and add images to a plot should they satisfy our criteria. We will first check if the image is a dog, by checking if the numpy attribute of the current label we are on is equal to 1. Additionally, we must check that we have not already entered the images for three dogs, by checking if numDog is less than three. Should this be true, we create a plot of dimensions (2,3) as we wish to have our plot contain two rows of three. We will then input this image into the plot at the first position. However as this is a loop, we cannot simply place 1, but rather we have to consider how the loop will deal with future images, which is where our numDogs variable will come in handy. We can send each image to the position 1+numDog in the plot, as they will each be placed one after another as we continually increment numDog. We can then use plt.imshow() to display our image, which can be called by using images[i].numpy(), as this image corresponds to the label we checked at the beginning of the if statement. Finally, we can set the title of our image to be label, turn off the axis, and increment our numDog and we are done with the first portion of our function. Placing our cats in the bottom row is very similar to what we just did, but with a few minor tweaks. First off, in our if statement condition, we want to ensure that the label is equal to 0, not 1. Secondly, as we want the cats to be on the bottom, we will add an extra three to their position in the plot, as they will then begin being placed in the bottom row. Other than that, as long as we make sure to use numCat in our position and incrementation instead of numDog, our cat placement should be complete. Finally, to ensure we finish as we place our final image in, we call a final if statement, where if both numCat and numDog are equal to or greater than three, we break out of our loop. After our loop has concluded, we can call plt.show() and our function is complete.\n\n# Calling visualization function defined above\ntwoRowVis()\n\n\n\n\n\n\n\n\nAs you can see, we call the function twoRowVis() that we created in the above code block, and it displays a row of three images with dogs followed by a row of three cat images. Notice how the labels above all the dogs are 1 and above all the cats are 0.\n\n# Creating a label iterator\nlabels_iterator=train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator()\n\nWe now will create a label iterator so that we can check the number of cats and dogs in our training dataset. To do so, we unbatch train_ds to get all of our information, and then use a lambda function to extract just the labels. Finally we use the as_numpy_iterator() function to transform it into an iterator, yielding the iterator we title labels_iterator.\n\n# Compute the number of cats (labelled 0) and dogs (labelled 1) in training data\ncatCounter = 0\ndogCounter = 0\nfor label in labels_iterator:\n  if label==0:\n    catCounter = catCounter+1\n  elif label==1:\n    dogCounter = dogCounter+1\n\nprint(\"Number of cats is: \", catCounter)\nprint(\"Number of dogs is: \", dogCounter)\n\nNumber of cats is:  4637\nNumber of dogs is:  4668\n\n\nHere we use our label iterator that we made prviously to caluclate the number of cats and dogs in our training dataset. We will create two variables that will be used to count the number of cats and dogs in our dataset, titled catCounter and dogCounter. Recall that cats are distinguished with a label of 0 while dogs have a label of 1. We use this information to run through the iterator, incrementing the catCounter when we find a label equal to zero, and incrementing dogCounter when we encounter a label equal to one. Finally, we print out our results and find that there is a similar number of cat and dog images, 4,637 and 4,668 respectively.\nThis information can be used to estimate the accuracy of a baseline learning model, a model that simply guesses the most frequent label each time. As we can see, there are more dogs in this dataset, therefore the baseline would guess dog every time. We can calculate the accuracy by taking how many times it would be correct over the total samples, yielding 4,668/9,305= 0.50166, or approximately 50.166% accuracy."
  },
  {
    "objectID": "posts/HW5/index.html#first-model",
    "href": "posts/HW5/index.html#first-model",
    "title": "HW 5: Image Classification with Keras",
    "section": "First Model",
    "text": "First Model\n\n# Create a sequential model\nmodel = keras.Sequential()\n\nmodel.add(layers.Input((150,150,3)))\n\n# Convolutional layers\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n\n# Flatten layer to convert 2D feature maps to a vector\nmodel.add(layers.Flatten())\n\n# Fully connected layers\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.5))  # Dropout layer to prevent overfitting\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nmodel.add(layers.Dense(2))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel.summary()\n\n\nModel: \"sequential_42\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_10 (Conv2D)          (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_8 (MaxPoolin  (None, 74, 74, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_11 (Conv2D)          (None, 72, 72, 64)        18496     \n                                                                 \n max_pooling2d_9 (MaxPoolin  (None, 36, 36, 64)        0         \n g2D)                                                            \n                                                                 \n flatten_8 (Flatten)         (None, 82944)             0         \n                                                                 \n dense_11 (Dense)            (None, 128)               10616960  \n                                                                 \n dropout_4 (Dropout)         (None, 128)               0         \n                                                                 \n dense_12 (Dense)            (None, 2)                 258       \n                                                                 \n=================================================================\nTotal params: 10636610 (40.58 MB)\nTrainable params: 10636610 (40.58 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\nWe will now create our first keras sequential model. We start by initializing our model, titled model, to be an instance of keras.Sequential(). Now we can begin introducing our layers. Firstly, as we know the dimensions of each of our inputs, we can give this information to the model by adding an Input layer, specifying that each input will be of size (150,150,3). We know the dimensions as we resized each image earlier to be of size (150,150), and then each image has rgb coloring, representing the final dimension of size 3. We can now begin adding our convolutional layers to our model. We start by adding a layer called Conv2D. These layers effectively sharpen the image passed through them by increasing the contrast between pixels by passing them through a kernel. They slightly change the size of the image, as we can see in our summary above by looking at the input it is passed in and observing the difference between its output. We then implement several MaxPooling2D layers. Put somewhat simply, these down-sample the spatial dimensions of the input, while retaining most of the important information. After two iterations of both of those layers, we call a Flatten layer, which converts its input into a one dimension. This then allows us to call Dense layers, which require a flattened input. Our first dense layer has an argument of 128 passed to it, meaning it is functioning with 128 neurons. After our first dense layer, we implement a dropout layer which excludes various nodes with a probability passed into it, with the intention to combat overfitting. Finally, we call a dense layer with only two categories so that the model can determine if the test image is either a cat or dog. You may notice that several of the layers have an activation argument introduced. These activations are mathematical functions applied to the output of a layer which serve as a way to introduce non-linearity into our model. Additionally, in our final dense layer, we see an optimizer and loss argument. These serve to help the network know what kind of loss it should be trying to avoid, as well as adjust weights and learning rates in order to get a more accurate final result. At the end of this layer, we call metrics = [‘accuracy’] to ensure that we can access information on the accuracy when we train the model. Finally, we call model.summary() to get the representation of the model we see outputted above.\n\n# Train model1 here\nhistory = model.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 9s 45ms/step - loss: 34.4208 - accuracy: 0.5546 - val_loss: 0.6768 - val_accuracy: 0.5851\nEpoch 2/20\n146/146 [==============================] - 6s 41ms/step - loss: 0.6592 - accuracy: 0.6056 - val_loss: 0.6878 - val_accuracy: 0.5469\nEpoch 3/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5968 - accuracy: 0.6607 - val_loss: 0.7046 - val_accuracy: 0.5516\nEpoch 4/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.5291 - accuracy: 0.7081 - val_loss: 0.7201 - val_accuracy: 0.5537\nEpoch 5/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.4597 - accuracy: 0.7640 - val_loss: 0.8601 - val_accuracy: 0.5542\nEpoch 6/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.4062 - accuracy: 0.7910 - val_loss: 1.0294 - val_accuracy: 0.5499\nEpoch 7/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.3546 - accuracy: 0.8291 - val_loss: 1.1475 - val_accuracy: 0.5641\nEpoch 8/20\n146/146 [==============================] - 5s 37ms/step - loss: 0.3557 - accuracy: 0.8409 - val_loss: 1.1655 - val_accuracy: 0.5817\nEpoch 9/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.2918 - accuracy: 0.8710 - val_loss: 1.3005 - val_accuracy: 0.5757\nEpoch 10/20\n146/146 [==============================] - 5s 35ms/step - loss: 0.2714 - accuracy: 0.8818 - val_loss: 1.1921 - val_accuracy: 0.5980\nEpoch 11/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.2664 - accuracy: 0.8803 - val_loss: 1.3563 - val_accuracy: 0.5791\nEpoch 12/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.2197 - accuracy: 0.9113 - val_loss: 1.6582 - val_accuracy: 0.5959\nEpoch 13/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.2045 - accuracy: 0.9192 - val_loss: 1.4596 - val_accuracy: 0.5911\nEpoch 14/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1848 - accuracy: 0.9258 - val_loss: 1.5829 - val_accuracy: 0.5959\nEpoch 15/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1898 - accuracy: 0.9336 - val_loss: 1.4334 - val_accuracy: 0.6023\nEpoch 16/20\n146/146 [==============================] - 5s 36ms/step - loss: 0.1580 - accuracy: 0.9423 - val_loss: 1.6742 - val_accuracy: 0.5954\nEpoch 17/20\n146/146 [==============================] - 6s 38ms/step - loss: 0.1628 - accuracy: 0.9394 - val_loss: 1.7273 - val_accuracy: 0.5911\nEpoch 18/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1370 - accuracy: 0.9485 - val_loss: 1.7679 - val_accuracy: 0.5795\nEpoch 19/20\n146/146 [==============================] - 5s 34ms/step - loss: 0.1312 - accuracy: 0.9556 - val_loss: 1.7821 - val_accuracy: 0.6010\nEpoch 20/20\n146/146 [==============================] - 5s 37ms/step - loss: 0.1199 - accuracy: 0.9583 - val_loss: 1.6738 - val_accuracy: 0.6062\n\n\nWe now will train our newly created model on our training dataset. We want to save this training so that we access the information later to get more information on how our training evolved over time. We initiate training with the fit() method, passing train_ds as an argument representing the dataset to train over, as well as the number of epochs we wish to run, and the validation dataset to test on after each dataset. We can note that our validation accuracy settled between 57% and 60% by the final epochs. This represents an improvement over our baseline which we calculated to have an accuracy of just over 50%. With regards to overfitting, we can observe there is definitely a prominent presence as our validation accuracy began to stagnate at around 60% while the training accuracy continued to improve, reaching above 95% accuracy. Note that the graph being referred to is displayed just below.\n\nplt.plot(history.history[\"accuracy\"])\nplt.plot(history.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nIn order to visualize how our model did, we plot the training accuracy as well as the validation accuracy accross each epoch. We can see in this case that our validation accuracy remained somewhat stagnant while our training accuracy continued to increase, a sign that overfitting became a significant factor."
  },
  {
    "objectID": "posts/HW5/index.html#second-model",
    "href": "posts/HW5/index.html#second-model",
    "title": "HW 5: Image Classification with Keras",
    "section": "Second Model",
    "text": "Second Model\n\n#Demonstrate flipping\nmodelFlip = keras.Sequential()\nmodelFlip.add(layers.RandomFlip())\n\n\nfor images, labels in train_ds.take(1):\n    plt.subplot(1, 3, 1)\n    plt.imshow(images[0].numpy().astype(\"uint8\"))\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n    plt.subplot(1, 3, 2)\n    plt.imshow(modelFlip(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Flipped Image\")\n    plt.axis(\"off\")\n    plt.subplot(1, 3, 3)\n    plt.imshow(modelFlip(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Flipped Image\")\n    plt.axis(\"off\")\n    plt.show()\n\n\n\n\n\n\n\n\n\nIn this section we are experimenting with data augmentation layers, more specifically RandomFlip() and RandomRotation(). Starting with RandomFlip() we start of by making a model with just a RandomFlip() layer in it. We can demonstrate what this layer does by passing images through it and displaying what is outputted. On the left we see the first image from our train_ds dataset, shown using pyplot. To find out what happens when using the flipped layer, we display the same image, however when passing the image to imshow(), we apply the model to the image. What comes out is a reflected version of our original image, as you can see in the middle. We can do this same process one more time, and as we can see from the third image, we get another flipped version of our original image, however this one is flipped horizontally instead of vertically. If we do not pass any arguments to RandomFlip() we can see from the above images that it can flip the images both vertically and horizontally. Should we want it to only be able to flip images vertically we can pass the argument ‘vertical’ into the layer, and we will only get vertical flips.\n\n#Demonstrate rotating\nmodelRotate = keras.Sequential()\nmodelRotate.add(layers.RandomRotation(factor = 0.2))\n\n#plt.figure(figsize=(10,10))\n\nfor images, labels in train_ds.take(1):\n    ax = plt.subplot(1, 3, 1)\n    plt.imshow(images[0].numpy().astype(\"uint8\"))\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n    #plt.show()\n    ax = plt.subplot(1,3,2)\n    plt.imshow(modelRotate(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Rotated Image\")\n    plt.axis(\"off\")\n    #plt.show()\n    ax = plt.subplot(1, 3, 3)\n    plt.imshow(modelRotate(images[0]).numpy().astype(\"uint8\"))\n    plt.title(\"Rotated Image\")\n    plt.axis(\"off\")\n    plt.show()\n\n\n\n\n\n\n\n\nSimilar to our RandomFlip() demonstration above, here we are showing what a RandomRotation() layer does to an image. Again, we have our original image on the left. We can see from the second image that when we apply a RandomRotation() layer to our image is slightly rotated, in this case clockwise. Running the image through the layer again results in a different rotation as seen in image three. The amount of rotation can be controlled by passing a rotation factor, in this case we used 0.2. This factor represents a factor of 2 Pi, which becomes the maximum roatation this layer will provide, given that 2 Pi is a complete spin.\n\n# Create a sequential model\nmodel2 = keras.Sequential()\nmodel2.add(layers.Input((150,150,3)))\n\n# Augmentation Layers\nmodel2.add(layers.RandomFlip('vertical'))\nmodel2.add(layers.RandomRotation(factor=0.2))\n\n\n# Convolutional layers\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel2.add(layers.Conv2D(32,(3,3), activation = 'relu'))\n# Dropout layer to prevent overfitting\nmodel2.add(layers.Dropout(0.1))\n\n# Flatten layer to convert 2D feature maps to a vector\nmodel2.add(layers.Flatten())\n\n# Fully connected layers\nmodel2.add(layers.Dense(64, activation='relu'))\n\n# Output layer\nmodel2.add(layers.Dense(2))\n\n# Compile the model\nmodel2.compile(optimizer=Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel2.summary()\n\n\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_1 (RandomFlip)  (None, 150, 150, 3)       0         \n                                                                 \n random_rotation_1 (RandomR  (None, 150, 150, 3)       0         \n otation)                                                        \n                                                                 \n conv2d_6 (Conv2D)           (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_5 (MaxPoolin  (None, 49, 49, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_7 (Conv2D)           (None, 47, 47, 32)        9248      \n                                                                 \n max_pooling2d_6 (MaxPoolin  (None, 15, 15, 32)        0         \n g2D)                                                            \n                                                                 \n conv2d_8 (Conv2D)           (None, 13, 13, 32)        9248      \n                                                                 \n max_pooling2d_7 (MaxPoolin  (None, 4, 4, 32)          0         \n g2D)                                                            \n                                                                 \n conv2d_9 (Conv2D)           (None, 2, 2, 32)          9248      \n                                                                 \n dropout_2 (Dropout)         (None, 2, 2, 32)          0         \n                                                                 \n flatten_2 (Flatten)         (None, 128)               0         \n                                                                 \n dense_4 (Dense)             (None, 64)                8256      \n                                                                 \n dense_5 (Dense)             (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 37026 (144.63 KB)\nTrainable params: 37026 (144.63 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\nThe main difference in between this model and the first one we created is in the augmentation layers we have been experimenting with. These are introduced at the beginning of the model, just after we define the input shape. Other than that we are essentially just building upon our previous model, with a couple key exceptions. When looking at our output Dense layer, our optimizer is slightly different than before, as we have Adam(learning_rate=0.0001) instead of just ‘adam’. As one may expect, Adam and ‘adam’ refer to the same optimizer, however we are now customizing it a bit by passing a specific learning_rate. A lower learning rate puts less emphasis on each sample and epoch, although too small a learning rate would lead to a model that learns very slowly. On the other hand, should we have a learning rate that is too high, we can experience severe oscillations within different epochs as there is a larger emphasis placed on each sample. It is important to find a good medium, and in our case, 0.0001 worked well for us to achieve our desired accuracy.\n\n# Train model2 here\nhistory2 = model2.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 10s 35ms/step - loss: 2.5473 - accuracy: 0.5241 - val_loss: 0.9332 - val_accuracy: 0.5279\nEpoch 2/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.8300 - accuracy: 0.5211 - val_loss: 0.7367 - val_accuracy: 0.5370\nEpoch 3/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.7409 - accuracy: 0.5369 - val_loss: 0.7065 - val_accuracy: 0.5610\nEpoch 4/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.7085 - accuracy: 0.5564 - val_loss: 0.6812 - val_accuracy: 0.5847\nEpoch 5/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6920 - accuracy: 0.5764 - val_loss: 0.6745 - val_accuracy: 0.5920\nEpoch 6/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6795 - accuracy: 0.5919 - val_loss: 0.6899 - val_accuracy: 0.5671\nEpoch 7/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6738 - accuracy: 0.5945 - val_loss: 0.6642 - val_accuracy: 0.6045\nEpoch 8/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6673 - accuracy: 0.5981 - val_loss: 0.6582 - val_accuracy: 0.6182\nEpoch 9/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6617 - accuracy: 0.6088 - val_loss: 0.6654 - val_accuracy: 0.5942\nEpoch 10/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6581 - accuracy: 0.6097 - val_loss: 0.6465 - val_accuracy: 0.6225\nEpoch 11/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6542 - accuracy: 0.6292 - val_loss: 0.6423 - val_accuracy: 0.6225\nEpoch 12/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6486 - accuracy: 0.6240 - val_loss: 0.6381 - val_accuracy: 0.6359\nEpoch 13/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.6472 - accuracy: 0.6302 - val_loss: 0.6160 - val_accuracy: 0.6647\nEpoch 14/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.6372 - accuracy: 0.6419 - val_loss: 0.6032 - val_accuracy: 0.6737\nEpoch 15/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.6298 - accuracy: 0.6460 - val_loss: 0.6041 - val_accuracy: 0.6741\nEpoch 16/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6194 - accuracy: 0.6629 - val_loss: 0.6151 - val_accuracy: 0.6582\nEpoch 17/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6200 - accuracy: 0.6600 - val_loss: 0.5982 - val_accuracy: 0.6720\nEpoch 18/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6175 - accuracy: 0.6625 - val_loss: 0.5862 - val_accuracy: 0.6909\nEpoch 19/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.6087 - accuracy: 0.6674 - val_loss: 0.5969 - val_accuracy: 0.6857\nEpoch 20/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.6002 - accuracy: 0.6790 - val_loss: 0.6147 - val_accuracy: 0.6745\n\n\nWe now will train our newly created model2 on our training dataset. We again want to save our training information so that we can analyze it afterwards. Similar to last time, we initiate training with the fit() method, passing train_ds as an argument representing the dataset to train over, as well as the number of epochs we wish to run, and the validation dataset to test on after each dataset, however this time we pass it to model2. We can note that our validation accuracy settled between 65% and 70% by the final epochs. This represents an improvement over our first model which we calculated to have an accuracy of between 57% and 60%. With regards to overfitting, there is not nearly as large of an issue as there was in our first model. Taking a look at the graph depicting training and validation accuracy, we can see that they have a similar trend and remain relatively close to each other throughout the epochs. Note that the graph being referred to is displayed just below.\n\n# Visualize training history for model2\nplt.plot(history2.history['accuracy'])\nplt.plot(history2.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nWe run the same code we did last time to plot our training and validation accuracy, except this time calling history2 instead of history. As we can observe, our validation and training accuracies move much more in unison than they did in the previous model."
  },
  {
    "objectID": "posts/HW5/index.html#third-model",
    "href": "posts/HW5/index.html#third-model",
    "title": "HW 5: Image Classification with Keras",
    "section": "Third Model",
    "text": "Third Model\n\ni = keras.Input(shape=(150, 150, 3))\n# The pixel values have the range of (0, 255), but many models will work better if rescaled to (-1, 1.)\n# outputs: `(inputs * scale) + offset`\nscale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\nx = scale_layer(i)\npreprocessor = keras.Model(inputs = i, outputs = x)\n\nHere we are defining a preprocessor that modifies the data before running it through the rest of the model. In this case scenario, we are changing the pixel values from a scale of (0,255), to a scale of (-1,1). Often, models work better when working with this kind of scale. We can see how this is achieved as each shape is rescaled by dividing by 127.5, which puts all pixels in the range of (0,2), and then we offset by -1 to shift the range to (-1,1).\n\n# Create a sequential model\nmodel3 = keras.Sequential()\nmodel3.add(layers.Input((150,150,3)))\n\n# Augmentation Layers\nmodel3.add(layers.RandomFlip('vertical'))\nmodel3.add(layers.RandomRotation(factor=0.2))\n\n# Adding preprocessor layer defined above\nmodel3.add(preprocessor)\n\n# Convolutional layers\nmodel3.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel3.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel3.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel3.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel3.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel3.add(layers.MaxPooling2D(pool_size=(3, 3)))\n\nmodel3.add(layers.Conv2D(32, (3,3), activation = 'relu'))\n\n# Dropout layer to prevent overfitting\nmodel3.add(layers.Dropout(0.1))\n\n# Flatten layer to convert 2D feature maps to a vector\nmodel3.add(layers.Flatten())\n\n# Fully connected layers\nmodel3.add(layers.Dense(64, activation='relu'))\n\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nmodel3.add(layers.Dense(2))\n\n# Compile the model\nmodel3.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel3.summary()\n\n\nModel: \"sequential_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_4 (RandomFlip)  (None, 150, 150, 3)       0         \n                                                                 \n random_rotation_4 (RandomR  (None, 150, 150, 3)       0         \n otation)                                                        \n                                                                 \n model (Functional)          (None, 150, 150, 3)       0         \n                                                                 \n conv2d_14 (Conv2D)          (None, 148, 148, 32)      896       \n                                                                 \n max_pooling2d_11 (MaxPooli  (None, 49, 49, 32)        0         \n ng2D)                                                           \n                                                                 \n conv2d_15 (Conv2D)          (None, 47, 47, 32)        9248      \n                                                                 \n max_pooling2d_12 (MaxPooli  (None, 15, 15, 32)        0         \n ng2D)                                                           \n                                                                 \n conv2d_16 (Conv2D)          (None, 13, 13, 32)        9248      \n                                                                 \n max_pooling2d_13 (MaxPooli  (None, 4, 4, 32)          0         \n ng2D)                                                           \n                                                                 \n conv2d_17 (Conv2D)          (None, 2, 2, 32)          9248      \n                                                                 \n dropout_4 (Dropout)         (None, 2, 2, 32)          0         \n                                                                 \n flatten_5 (Flatten)         (None, 128)               0         \n                                                                 \n dense_9 (Dense)             (None, 64)                8256      \n                                                                 \n dense_10 (Dense)            (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 37026 (144.63 KB)\nTrainable params: 37026 (144.63 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\nThe main difference between this model and model2 is that we are including the preprocessor we defined above. It is important to note that we are still including the data augmentation layers and have placed those before the preprocessor. This is because the job that the augmentation play is to slightly vary the data, which should then be passed to the preprocessor so it can take the varied data and apply the scale change to it. Looking closely we can see that we have applied the ‘vertical’ argument to the RandomFlip() layer, which we learned earlier allows RandomFlip() to flip layers vertically but not horizontally. Other than that, all of the key elements have remained the same from the previous model, so we are counting on the preprocessor to improve the results of our model.\n\n# Train model3 here\nhistory3 = model3.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 7s 32ms/step - loss: 0.6721 - accuracy: 0.5799 - val_loss: 0.6273 - val_accuracy: 0.6509\nEpoch 2/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.6251 - accuracy: 0.6531 - val_loss: 0.5766 - val_accuracy: 0.7008\nEpoch 3/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.5853 - accuracy: 0.6901 - val_loss: 0.5497 - val_accuracy: 0.7227\nEpoch 4/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5628 - accuracy: 0.7116 - val_loss: 0.5517 - val_accuracy: 0.7283\nEpoch 5/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.5452 - accuracy: 0.7232 - val_loss: 0.5312 - val_accuracy: 0.7446\nEpoch 6/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5285 - accuracy: 0.7347 - val_loss: 0.5059 - val_accuracy: 0.7597\nEpoch 7/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5290 - accuracy: 0.7347 - val_loss: 0.5148 - val_accuracy: 0.7584\nEpoch 8/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.5109 - accuracy: 0.7501 - val_loss: 0.4911 - val_accuracy: 0.7747\nEpoch 9/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4972 - accuracy: 0.7546 - val_loss: 0.4780 - val_accuracy: 0.7799\nEpoch 10/20\n146/146 [==============================] - 5s 32ms/step - loss: 0.4840 - accuracy: 0.7663 - val_loss: 0.4727 - val_accuracy: 0.7859\nEpoch 11/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4729 - accuracy: 0.7737 - val_loss: 0.4895 - val_accuracy: 0.7752\nEpoch 12/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4692 - accuracy: 0.7758 - val_loss: 0.4460 - val_accuracy: 0.7984\nEpoch 13/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.4573 - accuracy: 0.7876 - val_loss: 0.4501 - val_accuracy: 0.7889\nEpoch 14/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4480 - accuracy: 0.7920 - val_loss: 0.4467 - val_accuracy: 0.8005\nEpoch 15/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.4434 - accuracy: 0.7927 - val_loss: 0.4472 - val_accuracy: 0.7932\nEpoch 16/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4353 - accuracy: 0.8023 - val_loss: 0.4259 - val_accuracy: 0.8083\nEpoch 17/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4281 - accuracy: 0.8041 - val_loss: 0.4346 - val_accuracy: 0.8027\nEpoch 18/20\n146/146 [==============================] - 5s 31ms/step - loss: 0.4214 - accuracy: 0.8086 - val_loss: 0.4200 - val_accuracy: 0.8074\nEpoch 19/20\n146/146 [==============================] - 4s 30ms/step - loss: 0.4170 - accuracy: 0.8040 - val_loss: 0.4198 - val_accuracy: 0.8065\nEpoch 20/20\n146/146 [==============================] - 4s 31ms/step - loss: 0.4091 - accuracy: 0.8082 - val_loss: 0.4084 - val_accuracy: 0.8156\n\n\nAfter training model3, we can see that our preprocessor did in fact make a difference. After fitting the model on our training dataset as we did previously and saving the information to history3, we see an improvement in accuracy. For this model, our validation accuracy settled between 80% and 82% by the final epochs. This represents an even more drastic improvement over our first model which we calculated to have an accuracy of between 57% and 60%. With regards to overfitting, there is not nearly as large of an issue as there was in our first model. When looking at the graph depicting training and validation accuracy, we note that they remain very close to each other throughout the training, even closer than our second model was. Note that the graph being referred to is displayed just below.\n\n# Visualize training history for model2\nplt.plot(history3.history['accuracy'])\nplt.plot(history3.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nAgain we are using saved information in history3 to visualize our training history. We can see that in this case our validation and training accuracy appear to be even closer than they have been before,"
  },
  {
    "objectID": "posts/HW5/index.html#fourth-model",
    "href": "posts/HW5/index.html#fourth-model",
    "title": "HW 5: Image Classification with Keras",
    "section": "Fourth Model",
    "text": "Fourth Model\n\nIMG_SHAPE = (150, 150, 3)\nbase_model = keras.applications.MobileNetV3Large(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model.trainable = False\n\ni = keras.Input(shape=IMG_SHAPE)\nx = base_model(i, training = False)\nbase_model_layer = keras.Model(inputs = i, outputs = x)\n\nWARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n12683000/12683000 [==============================] - 0s 0us/step\n\n\nIn this model we plan on implementing a pre-existing model to see if it can improve our accuracy. Above we are reading in the model, titled base_model, from keras, and passing it the shape of our images via the variable IMG_SHAPE. We will then implement this base layer into our model.\n\n\n\n# Create a sequential model\nmodel4 = keras.Sequential()\nmodel4.add(layers.Input((150,150,3)))\n\n\n# Augmentation Layers\nmodel4.add(layers.RandomFlip())\nmodel4.add(layers.RandomRotation(factor=10.0))\n\n# Adding layer defined above\nmodel4.add(base_model_layer)\n\n#Flatten\nmodel4.add(layers.Flatten())\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nmodel4.add(layers.Dense(2))\n\n# Compile the model\nmodel4.compile(optimizer=Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nmodel4.summary()\n\n\nModel: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_2 (RandomFlip)  (None, 150, 150, 3)       0         \n                                                                 \n random_rotation_2 (RandomR  (None, 150, 150, 3)       0         \n otation)                                                        \n                                                                 \n model_1 (Functional)        (None, 5, 5, 960)         2996352   \n                                                                 \n flatten_3 (Flatten)         (None, 24000)             0         \n                                                                 \n dense_6 (Dense)             (None, 2)                 48002     \n                                                                 \n=================================================================\nTotal params: 3044354 (11.61 MB)\nTrainable params: 48002 (187.51 KB)\nNon-trainable params: 2996352 (11.43 MB)\n_________________________________________________________________\n\n\nAs we can observem, this model appears to be much simpler than the previous models we created. Just by looking at the summary we would assume so as it is simply much shorter than the other ones. However we must take into account the fact that we have an entirely separate model built into this one we just created. While we have not included any Conv2D or Pooling2D layers in this model, it is important to note that we have still included our augmentation layers, as well as a Flatten layer followed by a Dense layer to give us our output. You may be wondering why we decided not to include our preprocessor that we introduced in the previous model. The reason is that the base_model_layer that we just added includes its own preprocessing layers, eliminating the need for us to introduce more. Now that we have created our model4, we can train it and see what kind of improvements this new model will experience.\n\n# Train model4 here\nhistory4 = model4.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 15s 65ms/step - loss: 0.5579 - accuracy: 0.8296 - val_loss: 0.2166 - val_accuracy: 0.9428\nEpoch 2/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.3273 - accuracy: 0.9033 - val_loss: 0.2017 - val_accuracy: 0.9450\nEpoch 3/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.2922 - accuracy: 0.9110 - val_loss: 0.1732 - val_accuracy: 0.9518\nEpoch 4/20\n146/146 [==============================] - 6s 45ms/step - loss: 0.2633 - accuracy: 0.9192 - val_loss: 0.1664 - val_accuracy: 0.9518\nEpoch 5/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.2566 - accuracy: 0.9207 - val_loss: 0.1875 - val_accuracy: 0.9484\nEpoch 6/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.2350 - accuracy: 0.9254 - val_loss: 0.1847 - val_accuracy: 0.9480\nEpoch 7/20\n146/146 [==============================] - 7s 48ms/step - loss: 0.2170 - accuracy: 0.9316 - val_loss: 0.1949 - val_accuracy: 0.9497\nEpoch 8/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.2110 - accuracy: 0.9327 - val_loss: 0.1599 - val_accuracy: 0.9523\nEpoch 9/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.2034 - accuracy: 0.9344 - val_loss: 0.1425 - val_accuracy: 0.9561\nEpoch 10/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1978 - accuracy: 0.9381 - val_loss: 0.1415 - val_accuracy: 0.9561\nEpoch 11/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1816 - accuracy: 0.9387 - val_loss: 0.1616 - val_accuracy: 0.9506\nEpoch 12/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1700 - accuracy: 0.9424 - val_loss: 0.1419 - val_accuracy: 0.9609\nEpoch 13/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1661 - accuracy: 0.9466 - val_loss: 0.1701 - val_accuracy: 0.9506\nEpoch 14/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1755 - accuracy: 0.9364 - val_loss: 0.1695 - val_accuracy: 0.9536\nEpoch 15/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1624 - accuracy: 0.9430 - val_loss: 0.1845 - val_accuracy: 0.9484\nEpoch 16/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1585 - accuracy: 0.9477 - val_loss: 0.1422 - val_accuracy: 0.9561\nEpoch 17/20\n146/146 [==============================] - 7s 47ms/step - loss: 0.1541 - accuracy: 0.9461 - val_loss: 0.1587 - val_accuracy: 0.9523\nEpoch 18/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1592 - accuracy: 0.9496 - val_loss: 0.1443 - val_accuracy: 0.9592\nEpoch 19/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.1468 - accuracy: 0.9455 - val_loss: 0.1574 - val_accuracy: 0.9579\nEpoch 20/20\n146/146 [==============================] - 7s 46ms/step - loss: 0.1534 - accuracy: 0.9477 - val_loss: 0.1596 - val_accuracy: 0.9531\n\n\nAfter again fitting the model on our training dataset as we did previously and saving the information, we see a drastic improvement in our accuracy, largely due to the new model that we built off of. For this model, our validation accuracy settled between 94% and 96% by the final epochs. This represents a massive drastic improvement over our first model which we calculated to have an accuracy of between 57% and 60%. In fact, this is also a massive improvement over our second model, as we jumped up from around 80%. With regards to overfitting, we can see that the validation in fact experiences much higher accuracy rates than the training sets did. This is not typically a sign of overfitting, as for an overfit model normally the opposite is true. Note that the graph being referred to is displayed just below.\n\n# Visualize training history for model4\nplt.plot(history4.history['accuracy'])\nplt.plot(history4.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nAfter again graphing the training and validation accuracies, we can see that this most recent model has had by far the most success in predicting dogs and cats, peaking at around 94% success for training and 96% for validation. It is somewhat curious that the validation has a higher accuracy rate than the training does, as typically it is the other way around."
  },
  {
    "objectID": "posts/HW5/index.html#final-model",
    "href": "posts/HW5/index.html#final-model",
    "title": "HW 5: Image Classification with Keras",
    "section": "Final Model",
    "text": "Final Model\n\n#Create model and test against test dataset\nfinalModel = keras.Sequential()\n\nfinalModel.add(layers.Input((150,150,3)))\n\n\n# Augmentation Layers\nfinalModel.add(layers.RandomFlip())\nfinalModel.add(layers.RandomRotation(factor=0.2))\n\n# Adding layer defined above\nfinalModel.add(base_model_layer)\n\n#Adding convolution layer\nfinalModel.add(layers.GlobalMaxPooling2D())\n#finalModel.add(layers.Dropout(0.1))\n\n#Flatten\nfinalModel.add(layers.Flatten())\n\n# Output layer with binary classification (sigmoid activation for binary classification)\nfinalModel.add(layers.Dense(2))\n\n# Compile the model\nfinalModel.compile(optimizer=Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n\n# Print the model summary\nfinalModel.summary()\n\nModel: \"sequential_41\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n random_flip_23 (RandomFlip  (None, 150, 150, 3)       0         \n )                                                               \n                                                                 \n random_rotation_25 (Random  (None, 150, 150, 3)       0         \n Rotation)                                                       \n                                                                 \n model_1 (Functional)        (None, 5, 5, 960)         2996352   \n                                                                 \n global_max_pooling2d_2 (Gl  (None, 960)               0         \n obalMaxPooling2D)                                               \n                                                                 \n flatten_7 (Flatten)         (None, 960)               0         \n                                                                 \n dense_10 (Dense)            (None, 2)                 1922      \n                                                                 \n=================================================================\nTotal params: 2998274 (11.44 MB)\nTrainable params: 1922 (7.51 KB)\nNon-trainable params: 2996352 (11.43 MB)\n_________________________________________________________________\n\n\nFor our final model we are trying to get as accurate as possible. Seeing as our most recent model had an accuracy of around 95%, it does not make sense to deviate too much from that model. Hence, this model is very reminiscent of our previous one, with a couple of tweaks. After our base_model_layer, we have added a convolution layer, GlobalMaxPooling2D, and then from there it remains the same as before. Time to see how well our new model performs.\n\n# Train finalModel here\nfinalHistory = finalModel.fit(train_ds,\n                     epochs=20,\n                     validation_data=validation_ds)\n\nEpoch 1/20\n146/146 [==============================] - 12s 52ms/step - loss: 3.6604 - accuracy: 0.6235 - val_loss: 1.7367 - val_accuracy: 0.7747\nEpoch 2/20\n146/146 [==============================] - 7s 46ms/step - loss: 1.8534 - accuracy: 0.7533 - val_loss: 0.8666 - val_accuracy: 0.8706\nEpoch 3/20\n146/146 [==============================] - 7s 45ms/step - loss: 1.3031 - accuracy: 0.8169 - val_loss: 0.6475 - val_accuracy: 0.9007\nEpoch 4/20\n146/146 [==============================] - 6s 44ms/step - loss: 1.0832 - accuracy: 0.8459 - val_loss: 0.5191 - val_accuracy: 0.9187\nEpoch 5/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.9933 - accuracy: 0.8535 - val_loss: 0.4821 - val_accuracy: 0.9256\nEpoch 6/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.8703 - accuracy: 0.8693 - val_loss: 0.3995 - val_accuracy: 0.9359\nEpoch 7/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.8153 - accuracy: 0.8743 - val_loss: 0.3618 - val_accuracy: 0.9398\nEpoch 8/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.7676 - accuracy: 0.8766 - val_loss: 0.3670 - val_accuracy: 0.9428\nEpoch 9/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.7150 - accuracy: 0.8825 - val_loss: 0.3418 - val_accuracy: 0.9458\nEpoch 10/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.6984 - accuracy: 0.8853 - val_loss: 0.3390 - val_accuracy: 0.9471\nEpoch 11/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.6224 - accuracy: 0.8936 - val_loss: 0.3150 - val_accuracy: 0.9493\nEpoch 12/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.6338 - accuracy: 0.8944 - val_loss: 0.2945 - val_accuracy: 0.9510\nEpoch 13/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.5575 - accuracy: 0.8991 - val_loss: 0.2715 - val_accuracy: 0.9514\nEpoch 14/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.5561 - accuracy: 0.8985 - val_loss: 0.2700 - val_accuracy: 0.9527\nEpoch 15/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.5171 - accuracy: 0.9018 - val_loss: 0.2562 - val_accuracy: 0.9540\nEpoch 16/20\n146/146 [==============================] - 7s 45ms/step - loss: 0.5165 - accuracy: 0.9047 - val_loss: 0.2451 - val_accuracy: 0.9570\nEpoch 17/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.4918 - accuracy: 0.9060 - val_loss: 0.2509 - val_accuracy: 0.9553\nEpoch 18/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.4613 - accuracy: 0.9084 - val_loss: 0.2300 - val_accuracy: 0.9549\nEpoch 19/20\n146/146 [==============================] - 6s 43ms/step - loss: 0.4452 - accuracy: 0.9079 - val_loss: 0.2413 - val_accuracy: 0.9553\nEpoch 20/20\n146/146 [==============================] - 6s 44ms/step - loss: 0.4585 - accuracy: 0.9066 - val_loss: 0.2471 - val_accuracy: 0.9544\n\n\nWe can see that this model again experienced exceptional accuracy, settling at around 95% for the validation sets. However this time we are going to go a step further and test it on our test_ds dataset that we are yet to use.\n\n# Visualize training history for finalModel\nplt.plot(finalHistory.history['accuracy'])\nplt.plot(finalHistory.history['val_accuracy'])\nplt.gca().set(xlabel=\"epoch\", ylabel=\"training accuracy\")\n\n\n\n\n\n\n\n\nAfter again plotting validatin and training accuracy throughout the training process, it makes sense that this graph appears similar to that of our previous model, as the two models are very similar in nature.\n\nfinalModel.evaluate(test_ds)\n\n37/37 [==============================] - 1s 33ms/step - loss: 0.3433 - accuracy: 0.9441\n\n\n[0.3432992398738861, 0.9441100358963013]\n\n\nTo test our model on our test dataset, we call then method evaluate() and pass it test_ds, so that it knows what to test our model on. We can see that we achieve an accuracy of just over 94%, a very respectable result indeed."
  },
  {
    "objectID": "posts/HW4/index.html",
    "href": "posts/HW4/index.html",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "",
    "text": "Today we will be simulating two dimensional heat diffusion using tools such as numpy and jax. The goal of this project is to get us familiar with some jax functions, as well as the benefits and drawbacks of using jax. Let us begin!"
  },
  {
    "objectID": "posts/HW4/index.html#introduction",
    "href": "posts/HW4/index.html#introduction",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "",
    "text": "Today we will be simulating two dimensional heat diffusion using tools such as numpy and jax. The goal of this project is to get us familiar with some jax functions, as well as the benefits and drawbacks of using jax. Let us begin!"
  },
  {
    "objectID": "posts/HW4/index.html#imports",
    "href": "posts/HW4/index.html#imports",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Imports",
    "text": "Imports\n\nimport jax\nimport numpy as np\nimport time\nfrom matplotlib import pyplot as plt\nfrom jax.experimental import sparse\nfrom jax import jit\nimport jax.numpy as jnp\n#importing the equations from our heat_equations file\n%run heat_equations.ipynb\n#setting our values to be used in this example\nN = 101\nepsilon = 0.2\n\nThis block contains the necessary imports needed to run our project. Additionally, you can see we are calling for heat_equations.ipynb to run. This will allow us to access the functions we define within that file so that we can test their functionality within this notebook. Note that in this blog post, all functions have been placed within the same notebook to make the post easier to understand. Finally, we define both N and epsilon to values that we will be using throughout this example. Note that epsilon is used in updating our timestep and N will represent the dimensions of our grid state."
  },
  {
    "objectID": "posts/HW4/index.html#getting-the-matrix-a",
    "href": "posts/HW4/index.html#getting-the-matrix-a",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Getting the Matrix A",
    "text": "Getting the Matrix A\n\ndef get_A(N):\n    '''Defines our transition operator A given value N\n    Args:\n        N: Size of our vector u0 to be used.\n    Returns:\n        A: The NxN transition matrix that would be used for \n        a vector of size N\n    '''\n    \n    #define n to be N*N to be used as length of A\n    n = N * N\n    #Setting the diagonals to be -4 and 1 where necessary\n    diagonals = [-4 * np.ones(n), np.ones(n-1), np.ones(n-1), np.ones(n-N), np.ones(n-N)]\n    #setting all other values to zero\n    diagonals[1][(N-1)::N] = 0\n    diagonals[2][(N-1)::N] = 0\n    #combining diagonals to create matrix A\n    A = np.diag(diagonals[0]) + np.diag(diagonals[1], 1) + np.diag(diagonals[2], -1) + np.diag(diagonals[3], N) + np.diag(diagonals[4], -N)\n    return A\n\nThe purpose of this function is to create our transition operator A, given the desired size, passed in as N. We know that our matrix A is going to be of size (N2, N2), so in order to make our syntax clearer, we define n = N * N. The transition matrix follows a very distinct format for our model, which makes it easier to define for various sizes. It is made up of a diagonal full of -4, along with four other diagonals filled with ones. In order to implement this into our matrix, we are going to set our diagonals to be numpy arrays filled with our desired values, as seen in the diagonals list above. As we know that all other values are going to be equal to zero, we can use these diagonal arrays, and call np.diag to input these arrays as a diagonal portion of our matrix A. After that, our matrix A is completed and ready to be returned by this function."
  },
  {
    "objectID": "posts/HW4/index.html#advance-time-using-matrix-multiplication",
    "href": "posts/HW4/index.html#advance-time-using-matrix-multiplication",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Advance Time Using Matrix Multiplication",
    "text": "Advance Time Using Matrix Multiplication\n\ndef advance_time_matvecmul(A, u, epsilon):\n    \"\"\"Advances the simulation by one timestep, via matrix-vector multiplication\n    Args:\n        A: The 2d finite difference matrix\n        u: N x N grid state at timestep k\n        epsilon: stability constant\n\n    Returns:\n        N x N Grid state at timestep k+1\n    \"\"\"\n    \n    #update our u to the next time step using matrix multiplication\n    u = u + epsilon * (A @ u.flatten()).reshape((u.shape[0], u.shape[0]))\n    return u\n\nThis function utilizes matrix multiplication to advance our gridstate one timestep. As we can see, it is passed in three parameters, those being, A, u, and epsilon. A refers to the transition matrix used to change the current gridstate, represented by u, when moving to the next timestep. The scalar value epsilon plays a role in dictating the size of the change between timesteps. We can see that A is multiplied with u within our redefinition of u, however notice that u must be flattened before the multiplication takes place. We want our returned u vector to be the same shape as the inputted one, so after we multiply those two together, we will use the dimensions of the u that was passed in to reshape u back to its original dimensions. We then multiply by the scalar epsilon to determine the size of the change to be used, before adding the whole term to our initial u. As we are adding our initial u, it is intuitive that epsilon(Au) represents the change between timesteps in the diffusion model. Now that we have defined our u for the next timestep, we can return this value, concluding the functionality of this function."
  },
  {
    "objectID": "posts/HW4/index.html#testing-our-first-function",
    "href": "posts/HW4/index.html#testing-our-first-function",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Testing our first function",
    "text": "Testing our first function\n\n#defining our matrix A and creating a list to append our results to\nA = get_A(N)\nlistShow = []\n\nHere we are calling the function we defined get_A() in order to set our variable A to an A matrix of size (N,N). We also initialize an empty list in which we can store the progression of our heat map. This will allow us to visualize the progression of our heat diffusion later.\n\n%%timeit -r 1 -n 1\n#setting u0 to initial condition\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#using for loop to update our timestep 2700 times\nfor i in range(1, 2701):\n    #calling function to advance forward one timestep\n    u0 = advance_time_matvecmul(A, u0, epsilon)\n    if i%300 == 0:\n        #appending state every 300 steps and printing timestep for debugging\n        listShow.append([u0,i])\n        print(i)\n\n300\n600\n900\n1200\n1500\n1800\n2100\n2400\n2700\n1min 39s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n\n\nLots of things are happening here. First off, you can see that we are timing this block of code using the timeit function. We set both r and n to 1 as we only want to run and time the block of code once. Next we will initialize our u0 vector to be used within this example. As we have seen before, our initial condition is composed of a singular point of heat in the middle of our grid state. Therefore, our initial condition vector u0 will be entirely zeros with the exception of a 1 in the very middle. This is accomplished by creating an (N,N) numpy array filled with zeros, before setting the middle index of each dimension, found at N/2, and setting it to 1. Now we are ready to run our model. We chose to run it for 2700 timesteps, therefore we will make a loop that runs 2700 times, accomplished above via the for loop running i from 1 to 2700. Within each loop, we will update the timestep by setting our u0 equal to the advance_time_matvemul function that we pass in our matrix A, our current u0, and our epsilon. While this updates our timestep, every 300 steps we will append our u0 and the i value, which represents the timestep, to the list we initialized in the previous block. This will allow us to visualize the diffusion in the next step. Additionally, every 300 steps I also chose to print out i in order to be able to see the progression of the loop as this loop ends up taking a long time, 1 min and 39 secs in this case.\n\n#setting dimensions of image display\nrows=3\ncols = 3\n#defining variable to be used in display loop\nimg_count = 0\n#defining our display figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8,8))\n#looping through each element in our figure, setting each to a different timestep of our model saved in list listShow\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(listShow):\n            #setting each box in display equal to unique image from list\n            axes[i, j].imshow(listShow[img_count][0])\n            #incrementing img_count to let us traverse along the list\n            img_count+=1\n\n\n\n\n\n\n\n\nHere we can use the listShow list we appended our vectors to in order to visualize our data. We will start by determining the layout of our model. As we appended information every 300 steps out of 2700 total steps, we can calculate that we have a total of 9 pieces of information, making a (3,3) grid a very reasonable option. Hence, we define our rows and columns to be equal to 3. We will also define a img_count variable to be equal to zero. This variable will be used to keep track of how many images we have already plotted. Now we define our figure itself, creating a plot with three rows and three columns, defined using the row and columns variables we just defined. Now we are ready to fill the plot with our images. In order to traverse through our (3,3) grid, we will create a nested for loop, with the outer loop running along the rows and the inner loop running through each column. Now as long as our variable img_count is less than the length of listShow, we will place the image from the list into the plot at location (i,j), given by the two loops. Note that the index of the element of the list we wish to be accessing is given by img_show, making it critical that we increment it within the inner for loop. As you can see, the resulting figures show an expanding heat map, as the heat is diffused from the singular initial point outwards, expanding further as we traverse through more timesteps."
  },
  {
    "objectID": "posts/HW4/index.html#getting-sparse-matrix",
    "href": "posts/HW4/index.html#getting-sparse-matrix",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Getting Sparse Matrix",
    "text": "Getting Sparse Matrix\n\ndef get_sparse_A(N):\n    '''Returns a sparse form of our transition matrix A\n    Args:\n        N: Size of our vector u0 to be used\n    Returns:\n        A_sp_matrix: The sparse form of the NxN transition matrix \n        that would be used for a vector of size N \n    '''\n    \n    #get the matrix A corressponding to the passed value N\n    A = get_A(N)\n    #find sparse version of matrix A and set it to our return value \n    A_sp_matrix = sparse.BCOO.fromdense(A)\n    return A_sp_matrix\n\nThis function is relatively simple, as we have done most of the heavy lifting in our previous function get_A(). Our goal is to receive a size N, and using that create the sparse version of the transition matrix corresponding to that size. A good place to start is by creating the actual transition matrix itself, which we can now easily do by calling our get_A() function, passing in our size N. Now we have to convert this matrix to a sparse matrix. Luckily, the jax.expiremental library has a way to do this using the sparse library. To save our A sparse matrix into A_sp_matrix, we call sparse.BCOO.fromdense() and pass in our matrix A. This method will convert whatever matrix it receives into its sparse form, meaning only containing information on nonzero elements. Now that we have created our desired sparse matrix, we can return this value and conclude our function."
  },
  {
    "objectID": "posts/HW4/index.html#testing-sparse-matrix",
    "href": "posts/HW4/index.html#testing-sparse-matrix",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Testing Sparse Matrix",
    "text": "Testing Sparse Matrix\n\n#creating a list in which to append our new results and getting the sparse version of matrix A\nlistShow1=[]\nsp_A = get_sparse_A(N)\n\nHere we are defining another list we will append data to. Additionally, we call the get_sparse_A() in order to get a sparse version of our matrix A that will be passed to our advance_time_matvecmul function.\n\n%%timeit -r 1 -n 1\n#resetting u0 to initial condition\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#looping to increase timestep a total of 2700 times\nfor t in range(1, 2701):\n    #calling jitted version of function to advance timestep\n    #note that the matrix passed in is a sparse matrix\n    u0 = jit(advance_time_matvecmul)(sp_A, u0, epsilon)\n    if t%300 == 0:\n        #appending timestep information once every 300 steps, printing for debugging purposes\n        print(t)\n        listShow1.append([u0,t])\n\n300\n600\n900\n1200\n1500\n1800\n2100\n2400\n2700\n1.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n\n\nThis block of code is nearly identical to the one we used to test our previous function. We are again timing the code block using timeit, again are creating our initial condition within u0. However the loop is slightly different. We are still running for 2700 timesteps, appending data every 300 steps, but we can see that the function we call is slightly different. We have placed the command jit before the function. This creates a jitted version of our advance_time_matvecmul() function, which should in theory make this function run faster. This is accomplished by using just-in-time compilation, meaning it is compiled during runtime as opposed to before execution. Additionally, we can see that instead of passing the A matrix, we are passing the sparse verision of matrix A, denoted sp_A. This should in theory speed up the process as A was predominantly filled with zeros. Now that it is a sparse matrix, it can ignore multiplication with the zeros, drastically decreasing the time required to run the matrix multiplication within the advance_time_matvecmul() function. As we can see, these changes resulted in a drastic increase in speed, as we are now at 1.7 secs, drastically faster than the previous example.\n\n#defining dimensions of our display figure\nrows=3\ncols = 3\n#resetting variable to be used in display loop\nimg_count = 0\n#defining our display figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8,8))\n#looping through each element in our figure, setting each to a different timestep of our model, saved in list listShow1\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(listShow1):\n            #sets each box in display to different image in listShow1\n            axes[i, j].imshow(listShow1[img_count][0])\n            #increment img_count to traverse along the list\n            img_count+=1\n\n\n\n\n\n\n\n\nThis visualization process is the same as our previous one, except that we are pulling from listShow1 instead of listShow. However it is important that our visualizations resemble one another, as otherwise it would mean one of the two methods had some mistake. Yet upon inspection, we can see that these images appear very similar, if not identical, to our previous visualizations."
  },
  {
    "objectID": "posts/HW4/index.html#advancing-time-using-numpy",
    "href": "posts/HW4/index.html#advancing-time-using-numpy",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Advancing Time Using Numpy",
    "text": "Advancing Time Using Numpy\n\ndef advance_time_numpy(u, epsilon):\n    \"\"\"Advances simulation by one timestep using functions from numpy\n    Args:\n        u: NxN grid state at timestep k\n        epsilon: stability constant\n        \n    Returns: N x N Grid state at timestep k+1\n    \"\"\"\n    #get N so we know the size of matrix we are working with \n    m,N = u.shape\n    #create new matrix of size with two extra rows and columns\n    newU = np.zeros((N+2,N+2,),dtype='float64')\n    #set the center of new matrix equal to u, meaning ring of zeros around passed matrix u\n    newU[1:-1,1:-1] = u\n    #implement changes in x direction\n    u_xx = np.roll(newU, shift=1, axis=0) - 2 * newU + np.roll(newU, shift=-1, axis=0)\n    #implement changes in y direction\n    u_yy = np.roll(newU, shift=1, axis=1) - 2 * newU + np.roll(newU, shift=-1, axis=1)\n    #apply changes and set it equal to a new matrix\n    finU = newU + epsilon * (u_xx + u_yy)\n    #eliminate outer ring of values, allowing the heat to escape, setting equal to return value\n    u_new = finU[1:-1,1:-1]\n    return u_new\n\nThis method will give us a way to advance a timestep without the use of matrix multiplication. As matrix multiplication is expensive from a time standpoint, the hope is that by eliminating the need for it, w e will end up speeding up our advancement process. The first thing to note about this function is that we are only passed in two parameters, those being u and epsilon. Unlike our previous functions, we no longer have the variable N representing the size of our dimensions. Fortunately, we know that our gridstate u is of size (N,N), so our first step is to extract size N from the shape of u, shown in the first line of code. We will now create an empty matrix that will be used to adjust our current u, titled newU. You may notice that the new matrix is of different dimensions than our current u, two greater in each dimension in fact. This allows us to have some padding that later in the function we will take advantage of by using it to let head escape from our model. Therefore, to use this extra space as padding, we need to place our current u into the middle of our new matrix, which can be done by setting the indexed area in the middle of our new matrix equal to our current matrix u. Now is when the math comes in. Using the update equation in discrete time, we can see that for each point, the change is defined by adding heat from the points both to the left and right, as well as the points above and below, followed by a loss of four times the heat from the point itself. In order to implement this change, we are going to do it in two parts, one parat along the x-axis and another along the y-axis. While we could try and shift the matrix and then add it back to the original, the numpy roll() function will work well here, as it shifts all the elements along a given axis. It is important to note that the numpy roll function will send the last elements back to the beginning of the array, which could cause issues, however we have accounted for this possible issue via the padding we introduced earlier. Now, to define the change on the x-axis, we add a roll left and a roll right, along with a subtraction of two of the original matrix itself. Note that we define the roll along the x-axis by setting axis=0 and the shift left or right by defining shift=1 for right shift and shift=-1 for left shift. We now do the exact same thing for the y-axis, the only difference being that we set our axis=1. We can now implement our changes into a new matrix by adding the matrix newU to an espilon scaled factor of the changes, and assigning it to the matrix finU. We now have an updated version of our matrix set for the next timestep, however as a final step we need to remove the padding layer to simultaneously change our matrix back to the same size and to allow heat to escape. This is accomplished by simply indexing the middle of our finU matrix and setting it equal to our return value, u_new. Now, we have created our new u matrix to be used in the next timestep, allowing us to return u_new, concluding this function."
  },
  {
    "objectID": "posts/HW4/index.html#testing-numpy-function",
    "href": "posts/HW4/index.html#testing-numpy-function",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Testing Numpy Function",
    "text": "Testing Numpy Function\n\n#creating new list in which we will append our results\nnewList = []\n\nAgain creating a list that we will append our data to. This time we will call it newList.\n\n%%timeit -r 1 -n 1\n#resetting u0 to initial conditions\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#looping to increase timestep a total of 2700 times \nfor t in range(1, 2701):\n    #calling numpy function to advance timestep\n    u0 = advance_time_numpy(u0, epsilon)\n    if t%300==0:\n        #appending timestate information once every 300 steps, printing for debugging purposes\n        newList.append([u0,t])\n        print(t)\n\n300\n600\n900\n1200\n1500\n1800\n2100\n2400\n2700\n520 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n\n\nThis testing block of code is a gain very similar to the previous ones, with one main exception. In this block we are no longer calling advance_time_matvecmul(), but are calling advance_time_numpy() instead. Note that in this new function, we no longer need to pass an instance of A, as we are no longer utilizing matrix multiplication to advance our timestep. Apart from that, everything else remains identical to the previous tests, and we can see the improvement our new function yields as the loop only took 520 ms, less than a third of the time of our previous attempt.\n\n#setting the dimensions for our display figure\nrows=3\ncols = 3\n#resetting variable used in display loop\nimg_count = 0\n#defining our display figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8,8))\n#looping to fill our display figure\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(newList):\n            #setting each box in display equal to unique image from list newList\n            axes[i, j].imshow(newList[img_count][0])\n            #incrementing img_count to traverse to next list element\n            img_count+=1\n\n\n\n\n\n\n\n\nWe run through our visualization process, and can see that the heat plots yielded by the advance_time_numpy() function are the same as our previous visualizations, confirming it to be accurate."
  },
  {
    "objectID": "posts/HW4/index.html#advancing-time-using-jax",
    "href": "posts/HW4/index.html#advancing-time-using-jax",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Advancing Time Using Jax",
    "text": "Advancing Time Using Jax\n\ndef advance_time_jax(u, epsilon):\n    \"\"\"Advances simulation by one timestep using jax without using\n        matrix multiplication routines.\n    Args:\n        u: N x N grid state at timestep k\n        epsilon: stability constant\n        \n    Returns: N x N Grid state at timestep k+1\n    \"\"\"\n    #get N so that we know what size of matrix we are working with\n    m,N = u.shape\n    #create new matrix with two extra rows and columns\n    newU = jnp.zeros((N+2,N+2))\n    #set the center of the new matrix equal to the passed matrix u\n    newU = newU.at[1:-1,1:-1].add(u)\n    #define the changes to be implemented in the x direction\n    u_xx = jnp.roll(newU, shift=1, axis=0) - 2 * newU + jnp.roll(newU, shift=-1, axis=0)\n    #define the changes to be implemented in the y direction\n    u_yy = jnp.roll(newU, shift=1, axis=1) - 2 * newU + jnp.roll(newU, shift=-1, axis=1)\n    #implement the changes into a new matrix\n    finU = newU + epsilon * (u_xx + u_yy)\n    #setting the return value to the matrix with only desired values\n    u_new = finU[1:-1,1:-1]\n\n    return u_new\n\nThis method is very similar to our numpy function, with a couple key differences. Similar to the numpy function above, we want this function to advance our grid state through one timestep without using matrix multiplication. However, we plan on jitting this function, meaning that we will not be able to simply use indexing. Luckily, the jax numpy library has an add() method that will be useful in implementing similar strategies as we did in the previous function. We will again retrieve the dimension N from the size of u, and then create a new matrix with padding, titled newU. However we cannot directly access and change the indices of newU to place our current u in the center, so we add .add(u) to the indices to add it to the middle, creating our padded u that we can now work with. The changes we define in both the x and y directions are identical to the numpy function above, as well as the assignment of the new matrix finU, defined as the sum of newU and an epsilon scaled change. Now, to return, we create a new matrix, u_new, that is defined as the center of our finU matrix, again both resizing back to the same size as our original u and allowing heat to escape. Now, we can return u_new to conclude our function."
  },
  {
    "objectID": "posts/HW4/index.html#testing-jax-numpy-function",
    "href": "posts/HW4/index.html#testing-jax-numpy-function",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Testing Jax Numpy Function",
    "text": "Testing Jax Numpy Function\n\n#creating new list to be appended to\nnewList1 = []\n\nInitializing our final output list that we will append to in the following block of code.\n\n%%timeit -r 1 -n 1\n#resetting u0 to initial conditions\nu0 = np.zeros((N,N))\nu0[int(N/2), int(N/2)] = 1.0\n#looping to increase timestep a total of 2700 times\nfor t in range(1, 2701):\n    #using jax function to advance timestep by one\n    u0 = jit(advance_time_jax)(u0, epsilon)\n    if t%300 == 0:\n        #once every 300 steps append timestep information to list, printing step for debugging purposes\n        newList1.append([u0,t])\n        print(t)\n\n300\n600\n900\n1200\n1500\n1800\n2100\n2400\n2700\n291 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n\n\nThis block is only slightly altered from our previous loop, as in this case we are both calling a different function, advance_time_jax() and jitting it. You may be wondering why we did not jit our advance_time_numpy() function. This is because after jitting a function, there are certain rules that must be followed, for example you cannot change specific indices in an array. This rule was not followed by advance_time_numpy(), however we created advance_time_jax() with the idea of jitting it in mind, meaning it satisfies all the rules. We observe another significant improvement as this loop only took 291 ms to run, just over half the time of the previous iteration.\n\n#defining dimensions of display\nrows=3\ncols = 3\n#resetting variable used in display loop\nimg_count = 0\n#defining our figure\nfig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(8,8))\nfor i in range(rows):\n    for j in range(cols):        \n        if img_count &lt; len(newList1):\n            #filling each box with image from information in newList1\n            axes[i, j].imshow(newList1[img_count][0])\n            #incrementing to allow for traversal along list\n            img_count+=1\n\n\n\n\n\n\n\n\nAs our visualizations yielded by jax_advance_time() match up with the other three sets, we are confident that all functions are running as designed."
  },
  {
    "objectID": "posts/HW4/index.html#comparison",
    "href": "posts/HW4/index.html#comparison",
    "title": "HW 4: Heat diffusion with Jax",
    "section": "Comparison:",
    "text": "Comparison:\nWhen looking at the four methods that we have implemented, it is clear that the advance_time_matvecmul() method is by far the slowest at 1 minute and 39 seconds per loop while our final method, advance_time_jax() is the fastest at a mere 291 ms per loop. The method advance_time_numpy() and advance_time_jax() may seem relatively similar in speeds as there is less than a second separating their time to progress 2700 time steps, however in reality the jax method is a little less than twice as fast as the numpy method, at times of 291 ms and 520 ms respectively. That being said, they are both significantly faster than the sparse_advance_time_matvecmul() method at 1.7 seconds per loop , which itself is still much faster than the advance_time_matvecmul() which, as stated before, took approximately 1 minute and 39 seconds to advance our model through 2700 timesteps.\nWhen it comes to writing the functions, taking into account that I did not write the first method, I found the get_sparse_A() method the easiest to write, as I was simply building on the get_A() method I had previously written, and then writing one line to set my return value to a sparse matrix corresponding to the matrix returned by the get_A() function. Similarly, the get_A() function was relatively straightforward to write as I simply had to create a matrix and then edit three of the diagonals. I initially had some trouble when writing the advance_time_numpy() function as I was unsure of how to implement the boundary conditions that were to allow heat to escape from the model. Before successfuly completing the boundary condition, my results yielded in a heat map that began to take on an almost plus like shape as the heat began to reach the edges and simply wrap around to the other side. I solved this probliem by creating a matrix of dimensions (N+2)x(N+2), which allowed the heat to go to an outer ring, that was effectively deleted before returning the function, simulating the idea that the heat escaped outside of our model. Similar to the get_A_sparse() function, after writing the advance_time_numpy() function the advance_time_jax() function was relatively easy to implement. Conceptually it follows the same pattern as the numpy function, with the only catches being that jax does not allow for index assingment. To get around this, I found a function .at(), helping me to navigate around the matrices, and more importantly, I created new matrices at each step, meaning I was not altering any pre-existing matrices, but rather creating new ones which is allowed by jax."
  },
  {
    "objectID": "posts/bruinPage/index.html",
    "href": "posts/bruinPage/index.html",
    "title": "Analysis and Recommendations of Web Scraped Movie Data",
    "section": "",
    "text": "In this blog post, I’m going to create a web scraper that will allow us to recommend new movies based on shared actors with your favorite movie.\nThe first thing we are going to do is navigate to the website called TMDB, found at the URL https://www.themoviedb.org/ . We can now pick our favorite movie that will be the basis of our recommendations, mine is Harry Potter and the Philosopher’s Stone. Next, I navigated to the main movie page found at: https://www.themoviedb.org/movie/671-harry-potter-and-the-philosopher-s-stone This URL is important to save for later as it will be the starting point for our spider. Now we can start to create our spider. The first step is to type the following into the terminal:\nconda activate PIC16B-24W\nscrapy startproject TMDB_scraper\ncd TMDB_scraper\nThis command will activate the PIC16B-24W environment that we installed previously, create a scrapy project with the name TMDB_scraper on your computer, and then change the directory of your terminal to your newly created project. As we navigate to the TMDB_scraper folder, we see that there are various files within the project, however first we want to navigate to the file titled ‘settings.py’, and add the following line:\n    CLOSESPIDER_PAGECOUNT = 20\nThis will limit the number of pages our spider will visit initially, limiting the amount of data it will acquire when we are constructing and debugging. Additionally, I wrote the line:\nUSER_AGENT = 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'\nThis line helps to minimize the chance that the website identifies your spider as a bot and tries to block the web scraping process. Finally, it is time to begin writing our spider. Inside of our project folder, navigate into the spiders directory and create a new file titled ‘tmdb_spider.py’, and add the following chunk of code to the file:\nimport scrapy\n\n\nclass TmdbSpider(scrapy.Spider):\n\n    name = 'tmdb_spider'\n    \n    def __init__(self, subdir=None, *args, **kwargs):\n    \n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"]\nThis code chunk will allow us to run the spider for our movie of choice from the terminal by giving the subdirectory on the TMDB website as our extra argument. Now that we have a working spider, it is time to implement our three parsing methods: parse(self, response), parse_full_credits(self, response), and parse_actor_page(self, response).\nLet’s start with the parse(self, response) function. The role of this function is to navigate from our main movie page to the ‘Full Cast and Crew’ page. If we go back to our main movie page, and navigate to the ‘Full Cast and Crew’ page, we can see that the only change in our URL is there is now a ‘/cast’ at the end. That tells us, all we need to do to get to our cast page is to add ‘/cast’ to the end of our current URL, and send our spider to the page found by our new URL. As we can see in the function below, we define our new URL to be called ‘full_credits_url’ which is created by taking ‘response.url’, the URL of the page we’re on, and adding the string ‘/cast’ to the end. As we now have the URL for the page we want to navigate to, we yield a scrapy.Request to send our spider to the cast page, passing our new ‘full_credits_url’ as the URL parameter, and setting the callback to the parse_full_credits() function as we will now navigate to the full credits page.\ndef parse(self, response):\n\n        '''\n        This function takes us from the main movie page to the cast and credits page yielding the url of the full credit page to be parsed by the parse_full_credits\n        '''\n        \n        #modifies url in order to navigate to the cast page\n        \n        full_credits_url = response.url + '/cast'\n        \n        #sends spider to the full credit page\n        \n        yield scrapy.Request(url=full_credits_url, callback=self.parse_full_credits)\nNow that we have made it onto the full cast and credits page, we will work with the parse_full_credits(self, response) function that was called as we navigated to this page. The goal of this function is to find all the actors who played a role in the movie and send our spider to their individual pages to be parsed by our final function parse_actor_page(). Last time we were able to navigate to the cast page by simply adding ‘/cast’, however as each actor has their own distinct name and page, we will not be able to hardcode the new URL. In fact if you click on the first actor or actress in the list, in my case Daniel Radcliffe, we see that the URL for their individual page contains a seemingly arbitrary number followed by their name. In order to find the extension for each actor, let us navigate back to the full cast and credits page. By right clicking on the top actor or actress’s name, followed by clicking inspect, we can see where their name is stored in the HTML file. More importantly, just before where their name is stored in text, we see something similar to ‘ Daniel Radcliffe’. Should we navigate back to Mr. Radcliffe’s page, we can see that the the element defined as ‘href’ is the same as the URL extension for the page, after the ‘https://www.themoviedb.org/’ that all pages on the TMDB site begin with. Clearly this is critical information as it will allow us to navigate to the actor or actress’s page using their URL extension. Now, we simply need to find a way to access this information for all of the actors. As we go back to the cast and credits page and look at the line where the first name was stored, we can traverse backwards to the line starting with “&lt;li data-order=”0” data-credit-id=” and then up again to the line reading ‘&lt;ol class = “people credits”&gt;’. It is important to note the information of all the cast members, including their names and the ‘href’ URL extensions we are trying to extract are all located under this ol class. We want to access this class from the HTML file in order to use it in our function, which we will be able to accomplish using css selectors. By taking a look at the first line of code, we can see that in the selector, we start in the overarching ol class, before specifying to travel down through the li class and finally asking for the attribute ‘href’ located within a. One thing to note about this line is the ‘:not(.crew)’ following the ol class. This effectively tells the program that all we do not want the attributes of any of the crew members, but only the attributes of the actors. Additionally, the .extract() command at the end of the line effectively gathers the information from the location we specified in the selector, allowing us to assign it to our variable actor_selectors. This command returns a list of the URL extensions for every actor in the movie and stores it in the actor_selectors variable. Now that we have the URL extensions, we can finish this function in a similar manner to the initial parse() function by creating new URLs for the spider to follow. As we observed before, every actor page starts with ‘https://www.themoviedb.org/’, and is followed by a tail unique to each actor which we have stored in the actor_selectors list. Now, to send our spider to each actor page, we simply write a for loop that iterates through all of the actor extensions in our actor_selectors list, add the extension to the generic URL started mentioned above, and again send the spider to the new page addressed by our new URL saved as actor_page_url. Our yield scrapy.Request() is slightly different than the one we used in the previous function as instead of calling parse_full_credits(), we are going to call parse_actor_page() as the spider is now traveling to an individual actor page.\n def parse_full_credits(self, response):\n \n        '''\n        This function navigates from the response's full credits page to each actor's individual page to be parsed in the parse_actor_page() function.\n        '''\n        \n        #creates list of cast members, excluding the crew members\n        \n        actor_selectors = response.css('ol.people.credits:not(.crew) li div.info a::attr(href)').extract()\n        \n        #for loop iterates over actor list sending spider to each actor page\n        \n        for actor_ in actor_selectors:\n        \n            actor_page_url = 'https://www.themoviedb.org'+actor_\n            \n            yield scrapy.Request(url=actor_page_url, callback=self.parse_actor_page)\nWe have now reached our third and final parsing function, parse_actor_page(self, response). The goal of this function is to identify all the movies in which the individual played an acting role and yield dictionaries that contain the individual’s name with the title of the movie they played a role in. The first thing we must do is identify the name of the actor or actress whose page we are on. This will be a similar process to finding the actor page references in the previous function, however this time there is only one piece of data we wish to extract, making it even simpler. Let us continue with our Daniel Radcliffe example from earlier by navigating back to his actor page. By highlighting his name at the top of the page and then clicking on the inspect option, we can again see where his name is stored in the HTML file associated with this page. We can see it is located as an attribute under a class titled ‘h2 class=”title”&gt;’ which we will again be able to access via css selectors. As we can see from the first line of code below, in the css selector we start at the h2 title class and then traverse to the ‘a’ section in which the name is located. Different from last time, we add the command ‘::text’ afterwards to tell the program we want the text stored at this location as opposed to the href attribute which is what we were looking for in the previous function. It is also important to note that here we are using .extract_first() instead of .extract() as we want the name itself as a string instead of a list containing the name, which is accomplished by .extract_first() which extracts the first element of the list to be returned while .extract() would grab the entire list. The .strip() at the end of the line simply ensures that there is no whitespace before or after the name to keep everything neat and consistent. We now have the name of the individual who the page belongs to stored under the variable actor_name, meaning that now we only need to find the names of the movies in which they played an acting role. We will now again implement a similar method to extract the titles of the movies the actor played a role in. If we highlight the title of the first movie or show under the ‘Acting’ section and check where it is located in the HTML file, we find it is under one of many sections labeled ’\n\n’ which are all under a table class titled ‘credits list’. While we could try and simply use the css selectors to try and locate this class as before, we must notice that there are two other classes with the same title, which would clearly make it somewhat tricky for the program to decipher exactly which one we are trying to access. Taking a closer look at these three classes, we can observe an h3 line above each one which are identical except for one word in each, the different words being ‘Acting’, ‘Production’, and ‘Crew’. Clearly we want to access the one referring to the acting roles, as we are not concerned with production and crew roles, however we need to find a way to access the correct table under acting. By taking another glance at the HTML file, we can see that the three classes of interest are all located within a div class titled ‘credits_list’. We can take advantage of this by creating a list of all the h3 terms under this list via the command defining datCred. Now that we have the list, we can simply search for which h3 contains the word ‘Acting’ to find exactly which table we want by using a for loop to iterate through each h3 element in datCred. We check for acting by checking if ‘Acting’ is in the text of the h3 element, as found in the condition of the if statement within the for loop. Now that we have identified which h3 term we want to follow, we will take advantage of xpath, another kind of selector, which has a useful function called ‘following-sibling’. This specifier tells the selector to follow a sibling class, a class with the same parent and on the same level as the initially specified node, and we have then included the xpath to ‘table[1]’ in which the tr classes containing the movie names are located, saving it to the variable txt. We then use the Selector() function to make it so that we can access just the data under the location we specified as opposed to the entire response that scrapy has found. It is worth noting that to run this command we must import the selector library from scrapy.Selector at the top of the page, with the line of code shown just below:\nfrom scrapy.selector import Selector\nFinally, we use the subset of the response to extract the movie titles for the actor. This process is shown in the final for loop. We call all elements in ‘tablePick.css(‘table.credit_group tr’)’ to access all of the tr classes individually, and then set the movOrTvName to the text under the class ‘role’ and within the ‘tooltip’ class and as the bdi attribute in the HTML file. Finally, we yield a dictionary with the actor name that we found in the beginning of the function, and the movie name that we just found. This will loop through all of the movies that the actor played a character in, resulting in all of their movies being represented in their own dictionaries to be saved in a .csv file we will create next.\ndef parse_actor_page(self, response):\n\n        '''\n        This function parses the actor page, extracting both the actor name and the movies/shows they were in, yielding the dictionaries with the actor name and the movies they appear in.\n        '''\n        \n        #extracts actor name from page\n        \n        actor_name = response.css('h2.title a::text').extract_first().strip()\n        \n        #list of data under actor acting appearances\n        \n        datCred = response.css('div.credits_list h3')\n        \n        #filtering to just acting roles\n        \n        for h3 in datCred:\n        \n            if 'Acting' in h3.xpath('./text()').get():\n            \n                txt = h3.xpath('following-sibling::table[1]').get()\n                \n                break\n                \n        #making tablePick a selector used to follow to movie data\n        \n        tablePick = Selector(text = txt)\n        \n        #extract and yield movie/show name with the actor name\n        \n        for cred in tablePick.css('table.credit_group tr'):\n        \n            movOrTvName = cred.css('td.role a.tooltip bdi::text').get().strip()\n            \n            yield{'actor': actor_name, 'movie_or_TV_name' : movOrTvName}\nNow that we have finished writing our spider, we are ready to run it in order to scrape our desired data off of the TMDB website. The first thing we need to do is go back into the settings.py file and comment out the page count limit we implemented just before creating our spider to allow our spider to scrape all of the pages it is sent to. We can now go back to the terminal and run the following command:\nscrapy crawl tmdb_spider -o results.csv -a subdir=671-harry-potter-and-the-philosopher-s-stone\nNote that the command is all one on the same line. This command will tell our spider to crawl on the website for the first Harry Potter movie as given by the subdirectory, and will write all of the results in a file named ‘results.csv’. If we go back into the project folder, we can open the file we just created and we will see dictionaries represented by a table with one column containing the actor names and the other column containing the titles of the movies that respective actor appeared in. This is where we will access the results our spider was able to produce. We can now use this data to create our recommendations.\nOur first step in creating our recommendations is importing our necessary packages and reading in the data we just acquired and saved into results.csv, which can be done via the following code:\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n#reading in the data we scraped using our spider\ndf = pd.read_csv('/Users/jakebrowning/Desktop/PIC16B/TMDB_scraper/results.csv')\n#using for loop to create a counting function for how many actors are in each movie\nmovDict = {}\nfor el in df1:\n    if el in movDict.keys():\n        movDict[el] = movDict[el]+1\n    else:\n        movDict[el] = 1\n\n#adjusting my dictionaries for the pandas dataframe\nsortedMovDict = sorted(movDict.items(), key=lambda x:x[1], reverse=True)\nconvertedMovDict = dict(sortedMovDict)\n\n#putting the counted dictionary into a pandas dataframe and displaying the dataframe\ndfList = pd.DataFrame(list(convertedMovDict.items()),columns=['Movie Name','Number of Shared Actors'])\ndfList\nWe can see this yields a list of movies containing shared actors, ordered from most shared actors to least shared actors with our original movie.\n\n\n#creating lists of the top twenty movies and their numbert of actors\nmovN = []\nnumAct = []\ni=0\nwhile i &lt; 20:\n    movN.append(dfList['Movie Name'][i])\n    numAct.append(dfList['Number of Shared Actors'][i])\n    i = 1+i\n\n#changing order of list to be better displayed in the graph\nmovN.reverse()\nnumAct.reverse()\n\n#creating bar chart with top twenty movie recommendations, displaying how many shared actors in each movie\nmyChart = plt.barh(movN, numAct)\nplt.bar_label(myChart, labels=numAct, label_type=\"edge\")\nplt.title('Top Twenty Movie Recommendations')\nplt.xlabel('Number of Shared Actors')\nplt.ylabel('Movie Title')\nplt.show()\nThis leaves us with our top twenty recommendations, shown in decreasing order by the bar chart displayed below."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "16bhwblog",
    "section": "",
    "text": "HW 5: Image Classification with Keras\n\n\n\n\n\n\nweek 9\n\n\n\n\n\n\n\n\n\nMar 4, 2024\n\n\nJake Browning\n\n\n\n\n\n\n\n\n\n\n\n\nHW 4: Heat diffusion with Jax\n\n\n\n\n\n\nweek 6\n\n\n\n\n\n\n\n\n\nFeb 22, 2024\n\n\nJake Browning\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 3: Flask\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\nJake Browning\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 11, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis and Recommendations of Web Scraped Movie Data\n\n\n\n\n\n\nweek 6\n\n\n\n\n\n\n\n\n\nFeb 11, 2024\n\n\nJake Browning\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nFeb 8, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]